{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "sample_size = 24        # 56\n",
    "plots_dir = os.path.join('out', 'plots', f'n{sample_size}')\n",
    "calculations_dir = os.path.join('out', 'calculations', f'n{sample_size}')\n",
    "\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "os.makedirs(calculations_dir, exist_ok=True)\n",
    "\n",
    "metrics = {\n",
    "    'sb.bin': 'Stereotypical bias',\n",
    "    'acc_equality_diff.bin': 'Accuracy equality difference',\n",
    "    'acc_equality_ratio.bin': 'Accuracy equality ratio',\n",
    "    'disp_impact.bin': 'Disparate impact',\n",
    "    'equal_opp_diff.bin': 'Equal opportunity difference',\n",
    "    'equal_opp_ratio.bin': 'Equal opportunity ratio',\n",
    "    'neg_pred_parity_diff.bin': 'Negative predictive parity difference',\n",
    "    'neg_pred_parity_ratio.bin': 'Negative predictive parity ratio',\n",
    "    'pos_pred_parity_diff.bin': 'Positive predictive parity difference',\n",
    "    'pred_equality_diff.bin': 'Predictive equality difference',\n",
    "    'pred_equality_ratio.bin': 'Predictive equality ratio',\n",
    "    'pos_pred_parity_ratio.bin': 'Positive predictive parity ratio',\n",
    "    'stat_parity.bin': 'Statistical parity'\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "with open(path.join(calculations_dir, 'gr.bin'), 'rb') as f:\n",
    "    gr = pd.DataFrame(np.fromfile(f).astype(np.float16), columns=['gr'])\n",
    "\n",
    "with open(path.join(calculations_dir, 'ir.bin'), 'rb') as f:\n",
    "    ir = pd.DataFrame(np.fromfile(f).astype(np.float16), columns=['ir'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_plot(df, metric):\n",
    "    fig = ggplot(df, aes(x=metric, fill='typeVal'))\n",
    "    fig += geom_histogram(aes(y=after_stat('count / np.sum(count)')), bins=50)\n",
    "    fig += scale_fill_manual(values={'NaN': '#ca0020', 'not NaN': '#404040'}, guide=False)\n",
    "    fig += facet_grid('ir~gr', labeller='label_both')\n",
    "    fig += scale_x_continuous(labels=lambda lst: [x if x != -1.5 else 'NaN' for x in lst])\n",
    "    fig += theme_minimal()\n",
    "    fig += theme(figure_size=(16, 8))\n",
    "    fig += ggtitle(f'{metric} for selected IR & GR')\n",
    "    fig += ylab('Probability')\n",
    "    return fig\n",
    "\n",
    "ir_selected = [0.125, 0.5, 0.875]\n",
    "gr_selected = [0.125, 0.5, 0.875]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for metric_file, metric_name in metrics.items():\n",
    "    with open(path.join(calculations_dir, metric_file), 'rb') as f:\n",
    "        metric = pd.DataFrame(np.fromfile(f).astype(np.float16), columns=[metric_name])\n",
    "    df = pd.concat([gr, ir], axis=1)\n",
    "    df = pd.concat([df, metric], axis=1)\n",
    "    df = df.loc[df.ir.isin(ir_selected) & df.gr.isin(gr_selected)]\n",
    "    df.replace(np.nan, -1.5, inplace=True)\n",
    "    df['typeVal'] = np.where(df[metric_name] == -1.5, 'NaN', 'not NaN')\n",
    "\n",
    "    fig = get_plot(df, metric_name)\n",
    "    print(fig)\n",
    "    # TODO name\n",
    "    fig.save(path.join(plots_dir, f'{metric_name}_hist.png'), width=16, height=8, dpi=300)\n",
    "\n",
    "    del metric\n",
    "    del df\n",
    "    gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## matplotlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# same in matplotlib\n",
    "for metric_file, metric_name in metrics.items():\n",
    "    with open(path.join(calculations_dir, metric_file), 'rb') as f:\n",
    "        metric = pd.DataFrame(np.fromfile(f).astype(np.float16), columns=[metric_name])\n",
    "    df = pd.concat([gr, ir], axis=1)\n",
    "    df = pd.concat([df, metric], axis=1)\n",
    "    df = df.loc[df.ir.isin(ir_selected) & df.gr.isin(gr_selected)]\n",
    "    df.replace(np.nan, -1.5, inplace=True)\n",
    "    df['typeVal'] = np.where(df[metric_name] == -1.5, 'NaN', 'not NaN')\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "    for ir_val in ir_selected:\n",
    "        for gr_val in gr_selected:\n",
    "            df_tmp = df.loc[(df.ir == ir_val) & (df.gr == gr_val)]\n",
    "            ax.hist(df_tmp[metric_name], bins=100, alpha=0.5, label=f'ir={ir_val}, gr={gr_val}')\n",
    "    ax.set_title(f'{metric_name} for selected IR & GR')\n",
    "    ax.set_xlabel(metric_name)\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.legend()\n",
    "    fig.savefig(path.join(plots_dir, f'{metric_name}_matplotlib.png'), dpi=300)\n",
    "\n",
    "    del metric\n",
    "    del df\n",
    "    gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
