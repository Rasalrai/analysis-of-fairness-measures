{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Shared calculations for histograms and perfect fairness, for all metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZvJFJUMJc-3"
   },
   "source": [
    "## Import libraries and define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "frbcDgnJ80wQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "from utils import *     # metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N0C9QJbKjkDX"
   },
   "outputs": [],
   "source": [
    "data_cols = [\n",
    "    'i_tp',     # minority true positive\n",
    "    'i_fp',     # minority false positive\n",
    "    'i_tn',     # minority true negative\n",
    "    'i_fn',     # minority false negative\n",
    "    'j_tp',     # majority true positive\n",
    "    'j_fp',     # majority false positive\n",
    "    'j_tn',     # majority true negative\n",
    "    'j_fn',     # majority false negative\n",
    "]\n",
    "\n",
    "sample_size = 24        # 56\n",
    "\n",
    "calculations_dir = path.join('out', 'calculations', f'n{sample_size}')\n",
    "os.makedirs(calculations_dir, exist_ok=True)\n",
    "dataset_path = path.join('..', 'fairness-data-generator', 'out', f'Set(08,{sample_size}).bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SK8hWB3jkDY"
   },
   "source": [
    "# Get calculations\n",
    "As the dataset is quite large (4.2 Gb) we will write calculations to separate files in 2 stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3RXj2g1wILz"
   },
   "source": [
    "## Write calculations of the 1st half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bnGu5_3kaTaR",
    "outputId": "5acd9406-b43d-4784-ede3-f50fc60d8208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   i_tp  i_fp  i_tn  i_fn  j_tp  j_fp  j_tn  j_fn\n0    24     0     0     0     0     0     0     0\n1    23     1     0     0     0     0     0     0\n2    23     0     1     0     0     0     0     0\n3    23     0     0     1     0     0     0     0\n4    23     0     0     0     1     0     0     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>i_tp</th>\n      <th>i_fp</th>\n      <th>i_tn</th>\n      <th>i_fn</th>\n      <th>j_tp</th>\n      <th>j_fp</th>\n      <th>j_tn</th>\n      <th>j_fn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get half of the data\n",
    "with open(dataset_path, \"rb\") as f:\n",
    "    df = pd.DataFrame(pickle.load(f), columns=data_cols)\n",
    "\n",
    "halfIdx = int(df.shape[0] / 2)\n",
    "df = df.iloc[:halfIdx]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCq6NgtX7fye",
    "outputId": "a507ee6c-32ec-4e61-d0c4-fa7f6c46e88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1314787 entries, 0 to 1314786\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count    Dtype\n",
      "---  ------  --------------    -----\n",
      " 0   i_tp    1314787 non-null  int8 \n",
      " 1   i_fp    1314787 non-null  int8 \n",
      " 2   i_tn    1314787 non-null  int8 \n",
      " 3   i_fn    1314787 non-null  int8 \n",
      " 4   j_tp    1314787 non-null  int8 \n",
      " 5   j_fp    1314787 non-null  int8 \n",
      " 6   j_tn    1314787 non-null  int8 \n",
      " 7   j_fn    1314787 non-null  int8 \n",
      "dtypes: int8(8)\n",
      "memory usage: 10.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2O6H_sXVlJFr",
    "outputId": "8c7b1a56-9887-415a-a14c-0fc566d555c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'collections': 418, 'collected': 2146, 'uncollectable': 0},\n {'collections': 38, 'collected': 1113, 'uncollectable': 0},\n {'collections': 4, 'collected': 575, 'uncollectable': 0}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate half of GRs\n",
    "with open(path.join(calculations_dir,  \"gr.bin\"), \"wb+\") as f:\n",
    "    get_group_ratios(df).to_numpy().tofile(f)\n",
    "\n",
    "# Calculate half of IRs\n",
    "with open(path.join(calculations_dir,  \"ir.bin\"), \"wb+\") as f:\n",
    "    get_imbalance_ratios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"i_tpr.bin\"), \"wb+\") as f:\n",
    "    getTPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_tpr.bin\"), \"wb+\") as f:\n",
    "    getTPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"i_fpr.bin\"), \"wb+\") as f:\n",
    "    getFPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_fpr.bin\"), \"wb+\") as f:\n",
    "    getFPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"i_ppv.bin\"), \"wb+\") as f:\n",
    "    get_positive_predictive_value_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_ppv.bin\"), \"wb+\") as f:\n",
    "    get_positive_predictive_value_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"i_npv.bin\"), \"wb+\") as f:\n",
    "    get_negative_predictive_value_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_npv.bin\"), \"wb+\") as f:\n",
    "    get_negative_predictive_value_j(df).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"stat_parity.bin\"), \"wb+\") as f:\n",
    "    get_statistical_parity(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"disp_impact.bin\"), \"wb+\") as f:\n",
    "    get_disparate_impact(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"acc_equality_ratio.bin\"), \"wb+\") as f:\n",
    "    get_acc_equality_ratio(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"acc_equality_diff.bin\"), \"wb+\") as f:\n",
    "    get_acc_equality_diff(df).to_numpy().tofile(f)\n",
    "    \n",
    "# Free the memory\n",
    "del df\n",
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ1G6RB4wdby"
   },
   "source": [
    "## Append calculations of the 2st half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kYg-MGrluBpp"
   },
   "outputs": [],
   "source": [
    "with open(dataset_path, \"rb\") as f:\n",
    "    df = pd.DataFrame(pickle.load(f), columns=data_cols)\n",
    "\n",
    "halfIdx = int(df.shape[0] / 2)\n",
    "df = df.iloc[halfIdx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZI6GFaih2eBR",
    "outputId": "3dfac9f1-d67b-42c4-f04a-10a7a860ffcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'collections': 421, 'collected': 2146, 'uncollectable': 0},\n {'collections': 38, 'collected': 1113, 'uncollectable': 0},\n {'collections': 5, 'collected': 575, 'uncollectable': 0}]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir,  \"gr.bin\"), \"ab+\") as f:\n",
    "    get_group_ratios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"ir.bin\"), \"ab+\") as f:\n",
    "    get_imbalance_ratios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"i_tpr.bin\"), \"ab+\") as f:\n",
    "    getTPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_tpr.bin\"), \"ab+\") as f:\n",
    "    getTPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"i_fpr.bin\"), \"ab+\") as f:\n",
    "    getFPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_fpr.bin\"), \"ab+\") as f:\n",
    "    getFPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"i_ppv.bin\"), \"ab+\") as f:\n",
    "    get_positive_predictive_value_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_ppv.bin\"), \"ab+\") as f:\n",
    "    get_positive_predictive_value_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"i_npv.bin\"), \"ab+\") as f:\n",
    "    get_negative_predictive_value_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_npv.bin\"), \"ab+\") as f:\n",
    "    get_negative_predictive_value_j(df).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"stat_parity.bin\"), \"ab+\") as f:\n",
    "    get_statistical_parity(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"disp_impact.bin\"), \"ab+\") as f:\n",
    "    get_disparate_impact(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"acc_equality_ratio.bin\"), \"ab+\") as f:\n",
    "    get_acc_equality_ratio(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"acc_equality_diff.bin\"), \"ab+\") as f:\n",
    "    get_acc_equality_diff(df).to_numpy().tofile(f)\n",
    "    \n",
    "del df\n",
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq72mH7zjkDo",
    "outputId": "3c68f020-7283-4b07-b1cb-a5f51d515ad7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -lah calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeeOR3sTjkDo"
   },
   "source": [
    "The files are written as `float64`, while the dataset has data-type `int8`, thus the size of each file is the same as the size of the dataset because each of them contains one 8 times heavier column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOT3O2yajkDp"
   },
   "source": [
    "# Get additional calculations\n",
    "These calculations will be based on the previous ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoYzFfdDjkDq"
   },
   "source": [
    "## Write 1st part\n",
    "Here the story is even worse as we need to open 2 files of the same size, so we will do it the same way: in 2 stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HURjnxCvoz20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir,  \"i_tpr.bin\"), \"rb\") as f:\n",
    "    i_tpr = pd.DataFrame(np.fromfile(f), columns=[\"i_tpr\"])\n",
    "    halfIdx = int(i_tpr.shape[0] / 2)\n",
    "    i_tpr = i_tpr.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_tpr.bin\"), \"rb\") as f:\n",
    "    j_tpr = pd.DataFrame(np.fromfile(f), columns=[\"j_tpr\"])\n",
    "    halfIdx = int(j_tpr.shape[0] / 2)\n",
    "    j_tpr = j_tpr.iloc[:halfIdx]\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"equal_opp_ratio.bin\"), \"wb+\") as f:\n",
    "    get_equal_opp_ratio(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"equal_opp_diff.bin\"), \"wb+\") as f:\n",
    "    get_equal_opp_diff(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "\n",
    "del j_tpr\n",
    "del i_tpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VBH3rVXMjkDt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir,  \"i_fpr.bin\"), \"rb\") as f:\n",
    "    i_fpr = pd.DataFrame(np.fromfile(f), columns=[\"i_fpr\"])\n",
    "    halfIdx = int(i_fpr.shape[0] / 2)\n",
    "    i_fpr = i_fpr.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_fpr.bin\"), \"rb\") as f:\n",
    "    j_fpr = pd.DataFrame(np.fromfile(f), columns=[\"j_fpr\"])\n",
    "    halfIdx = int(j_fpr.shape[0] / 2)\n",
    "    j_fpr = j_fpr.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"pred_equality_ratio.bin\"), \"wb+\") as f:\n",
    "    get_pred_equality_ratio(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"pred_equality_diff.bin\"), \"wb+\") as f:\n",
    "    get_pred_equality_diff(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "del j_fpr\n",
    "del i_fpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "whFb_KUEjkDu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir,  \"i_ppv.bin\"), \"rb\") as f:\n",
    "    i_ppv = pd.DataFrame(np.fromfile(f), columns=[\"i_ppv\"])\n",
    "    halfIdx = int(i_ppv.shape[0] / 2)\n",
    "    i_ppv = i_ppv.iloc[:halfIdx]\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"j_ppv.bin\"), \"rb\") as f:\n",
    "    j_ppv = pd.DataFrame(np.fromfile(f), columns=[\"j_ppv\"])\n",
    "    halfIdx = int(j_ppv.shape[0] / 2)\n",
    "    j_ppv = j_ppv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"pred_parity_ratio.bin\"), \"wb+\") as f:\n",
    "    get_pred_parity_ratio(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"pos_pred_parity_diff.bin\"), \"wb+\") as f:\n",
    "    get_pos_pred_parity_diff(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_ppv\n",
    "del i_ppv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_DKvl3w7jkDv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir,  \"i_npv.bin\"), \"rb\") as f:\n",
    "    i_npv = pd.DataFrame(np.fromfile(f), columns=[\"i_npv\"])\n",
    "    halfIdx = int(i_npv.shape[0] / 2)\n",
    "    i_npv = i_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_npv.bin\"), \"rb\") as f:\n",
    "    j_npv = pd.DataFrame(np.fromfile(f), columns=[\"j_npv\"])\n",
    "    halfIdx = int(j_npv.shape[0] / 2)\n",
    "    j_npv = j_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"neg_pred_parity_ratio.bin\"), \"wb+\") as f:\n",
    "    get_neg_pred_parity_ratio(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"neg_pred_parity_diff.bin\"), \"wb+\") as f:\n",
    "    get_neg_pred_parity_diff(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_npv\n",
    "del i_npv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRMFty8ajkDv"
   },
   "source": [
    "## Append 2nd part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Bx8lLzTajkDw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir,  \"i_tpr.bin\"), \"rb\") as f:\n",
    "    i_tpr = pd.DataFrame(np.fromfile(f), columns=[\"i_tpr\"])\n",
    "    halfIdx = int(i_tpr.shape[0] / 2)\n",
    "    i_tpr = i_tpr.iloc[halfIdx:]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_tpr.bin\"), \"rb\") as f:\n",
    "    j_tpr = pd.DataFrame(np.fromfile(f), columns=[\"j_tpr\"])\n",
    "    halfIdx = int(j_tpr.shape[0] / 2)\n",
    "    j_tpr = j_tpr.iloc[halfIdx:]\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"equal_opp_ratio.bin\"), \"ab+\") as f:\n",
    "    get_equal_opp_ratio(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"equal_opp_diff.bin\"), \"ab+\") as f:\n",
    "    get_equal_opp_diff(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "\n",
    "del j_tpr\n",
    "del i_tpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_IGQKxACjkDx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir,  \"i_fpr.bin\"), \"rb\") as f:\n",
    "    i_fpr = pd.DataFrame(np.fromfile(f), columns=[\"i_fpr\"])\n",
    "    halfIdx = int(i_fpr.shape[0] / 2)\n",
    "    i_fpr = i_fpr.iloc[halfIdx:]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_fpr.bin\"), \"rb\") as f:\n",
    "    j_fpr = pd.DataFrame(np.fromfile(f), columns=[\"j_fpr\"])\n",
    "    halfIdx = int(j_fpr.shape[0] / 2)\n",
    "    j_fpr = j_fpr.iloc[halfIdx:]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"pred_equality_ratio.bin\"), \"ab+\") as f:\n",
    "    get_pred_equality_ratio(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"pred_equality_diff.bin\"), \"ab+\") as f:\n",
    "    get_pred_equality_diff(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "del j_fpr\n",
    "del i_fpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2SHgiWRQjkDy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir,  \"i_ppv.bin\"), \"rb\") as f:\n",
    "    i_ppv = pd.DataFrame(np.fromfile(f), columns=[\"i_ppv\"])\n",
    "    halfIdx = int(i_ppv.shape[0] / 2)\n",
    "    i_ppv = i_ppv.iloc[halfIdx:]\n",
    "    \n",
    "with open(path.join(calculations_dir,  \"j_ppv.bin\"), \"rb\") as f:\n",
    "    j_ppv = pd.DataFrame(np.fromfile(f), columns=[\"j_ppv\"])\n",
    "    halfIdx = int(j_ppv.shape[0] / 2)\n",
    "    j_ppv = j_ppv.iloc[halfIdx:]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"pred_parity_ratio.bin\"), \"ab+\") as f:\n",
    "    get_pred_parity_ratio(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"pos_pred_parity_diff.bin\"), \"ab+\") as f:\n",
    "    get_pos_pred_parity_diff(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_ppv\n",
    "del i_ppv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_BKX-a8CjkDz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir,  \"i_npv.bin\"), \"rb\") as f:\n",
    "    i_npv = pd.DataFrame(np.fromfile(f), columns=[\"i_npv\"])\n",
    "    halfIdx = int(i_npv.shape[0] / 2)\n",
    "    i_npv = i_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"j_npv.bin\"), \"rb\") as f:\n",
    "    j_npv = pd.DataFrame(np.fromfile(f), columns=[\"j_npv\"])\n",
    "    halfIdx = int(j_npv.shape[0] / 2)\n",
    "    j_npv = j_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir,  \"neg_pred_parity_ratio.bin\"), \"ab+\") as f:\n",
    "    get_neg_pred_parity_ratio(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir,  \"neg_pred_parity_diff.bin\"), \"ab+\") as f:\n",
    "    get_neg_pred_parity_diff(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_npv\n",
    "del i_npv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations for sonya plot\n",
    "\n",
    "(extended in `ppf_calculations.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sonya(df, ratio_type):\n",
    "    diff_metrics = {\n",
    "        'acc_equality_diff.bin': 'Accuracy equality difference', \n",
    "        'equal_opp_diff.bin': 'Equal opportunity difference', \n",
    "        'neg_pred_parity_diff.bin': 'Negative predictive parity difference', \n",
    "        'pos_pred_parity_diff.bin': 'Positive predictive parity difference', \n",
    "        'pred_equality_diff.bin': 'Predictive equality difference',\n",
    "        'stat_parity.bin': 'Statistical parity'\n",
    "    }\n",
    "    \n",
    "    diff_probs = {}\n",
    "    compute_diff_prob = lambda df: np.sum(df['diff'] == 0) / len(df)\n",
    "    \n",
    "    for metricFName in diff_metrics:\n",
    "        with open(path.join(calculations_dir,  metricFName), \"rb\") as f:\n",
    "            diff_metric = pd.DataFrame(np.fromfile(f).astype(np.float16), columns=[\"diff\"])\n",
    "        df = pd.concat([df, diff_metric], axis=1)\n",
    "\n",
    "        diff = df.groupby(ratio_type).apply(compute_diff_prob)\n",
    "        diff_probs[diff_metrics[metricFName]] = diff\n",
    "\n",
    "        df.drop('diff', axis=1, inplace=True)\n",
    "        \n",
    "    sonya = pd.DataFrame(diff_probs)\n",
    "    sonya.reset_index(inplace=True)\n",
    "    sonya.to_csv(path.join(calculations_dir, f\"ppf_{ratio_type}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "for ratio in ['gr', 'ir']:\n",
    "    with open(path.join(calculations_dir, f\"{ratio}.bin\"), \"rb\") as f:\n",
    "        df = pd.DataFrame(np.fromfile(f).astype(np.float16), columns=[ratio])\n",
    "    calculate_sonya(df, ratio)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f011426f63b937df9084534402d60726e75436353eed0d60e767a35eaa72376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
