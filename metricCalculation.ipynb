{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZvJFJUMJc-3"
   },
   "source": [
    "# Import libraries and define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "frbcDgnJ80wQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import glob\n",
    "from os import path\n",
    "from utils import * # metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N0C9QJbKjkDX"
   },
   "outputs": [],
   "source": [
    "dataCols = ['i_tp', 'i_fp', 'i_tn', 'i_fn', 'j_tp', 'j_fp', 'j_tn', 'j_fn']\n",
    "calculationsDir = \"out/calculations/\"\n",
    "datasetName = path.join('..', 'fairness-measures-gen', 'out', \"Set(08,56).bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SK8hWB3jkDY"
   },
   "source": [
    "# Get calculations\n",
    "As the dataset is quite large (4.2 Gb) we will write calculations to separate files in 2 stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3RXj2g1wILz"
   },
   "source": [
    "## Write calculations of the 1st half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bnGu5_3kaTaR",
    "outputId": "5acd9406-b43d-4784-ede3-f50fc60d8208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   i_tp  i_fp  i_tn  i_fn  j_tp  j_fp  j_tn  j_fn\n0    56     0     0     0     0     0     0     0\n1    55     1     0     0     0     0     0     0\n2    55     0     1     0     0     0     0     0\n3    55     0     0     1     0     0     0     0\n4    55     0     0     0     1     0     0     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>i_tp</th>\n      <th>i_fp</th>\n      <th>i_tn</th>\n      <th>i_fn</th>\n      <th>j_tp</th>\n      <th>j_fp</th>\n      <th>j_tn</th>\n      <th>j_fn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get half of the data\n",
    "with open(datasetName, \"rb\") as f:\n",
    "    df = pd.DataFrame(pickle.load(f), columns = dataCols)\n",
    "\n",
    "halfIdx = int(df.shape[0] / 2)\n",
    "df = df.iloc[:halfIdx]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCq6NgtX7fye",
    "outputId": "a507ee6c-32ec-4e61-d0c4-fa7f6c46e88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276635335 entries, 0 to 276635334\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   i_tp    int8 \n",
      " 1   i_fp    int8 \n",
      " 2   i_tn    int8 \n",
      " 3   i_fn    int8 \n",
      " 4   j_tp    int8 \n",
      " 5   j_fp    int8 \n",
      " 6   j_tn    int8 \n",
      " 7   j_fn    int8 \n",
      "dtypes: int8(8)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2O6H_sXVlJFr",
    "outputId": "8c7b1a56-9887-415a-a14c-0fc566d555c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'collections': 425, 'collected': 2369, 'uncollectable': 0},\n {'collections': 38, 'collected': 1201, 'uncollectable': 0},\n {'collections': 4, 'collected': 2065, 'uncollectable': 0}]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate half of GRs\n",
    "with open(calculationsDir + \"gr.bin\", \"wb+\") as f:\n",
    "    getGroupRatios(df).to_numpy().tofile(f)\n",
    "\n",
    "# Calculate half of IRs\n",
    "with open(calculationsDir + \"ir.bin\", \"wb+\") as f:\n",
    "    getImbalanceRatios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_tpr.bin\", \"wb+\") as f:\n",
    "    getTPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_tpr.bin\", \"wb+\") as f:\n",
    "    getTPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_fpr.bin\", \"wb+\") as f:\n",
    "    getFPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_fpr.bin\", \"wb+\") as f:\n",
    "    getFPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_ppv.bin\", \"wb+\") as f:\n",
    "    getPositivePredictiveValue_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_ppv.bin\", \"wb+\") as f:\n",
    "    getPositivePredictiveValue_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_npv.bin\", \"wb+\") as f:\n",
    "    getNegativePredictiveValue_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_npv.bin\", \"wb+\") as f:\n",
    "    getNegativePredictiveValue_j(df).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"stat_parity.bin\", \"wb+\") as f:\n",
    "    get_statistical_parity(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"disp_impact.bin\", \"wb+\") as f:\n",
    "    get_disparate_impact(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"acc_equality_ratio.bin\", \"wb+\") as f:\n",
    "    get_acc_equality_ratio(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"acc_equality_diff.bin\", \"wb+\") as f:\n",
    "    get_acc_equality_diff(df).to_numpy().tofile(f)\n",
    "    \n",
    "# Free the memory\n",
    "del df\n",
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ1G6RB4wdby"
   },
   "source": [
    "## Append calculations of the 2st half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kYg-MGrluBpp"
   },
   "outputs": [],
   "source": [
    "with open(datasetName, \"rb\") as f:\n",
    "    df = pd.DataFrame(pickle.load(f), columns = dataCols)\n",
    "\n",
    "halfIdx = int(df.shape[0] / 2)\n",
    "df = df.iloc[halfIdx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZI6GFaih2eBR",
    "outputId": "3dfac9f1-d67b-42c4-f04a-10a7a860ffcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'collections': 427, 'collected': 2369, 'uncollectable': 0},\n {'collections': 38, 'collected': 1201, 'uncollectable': 0},\n {'collections': 5, 'collected': 2065, 'uncollectable': 0}]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"gr.bin\", \"ab+\") as f:\n",
    "    getGroupRatios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"ir.bin\", \"ab+\") as f:\n",
    "    getImbalanceRatios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_tpr.bin\", \"ab+\") as f:\n",
    "    getTPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_tpr.bin\", \"ab+\") as f:\n",
    "    getTPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_fpr.bin\", \"ab+\") as f:\n",
    "    getFPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_fpr.bin\", \"ab+\") as f:\n",
    "    getFPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_ppv.bin\", \"ab+\") as f:\n",
    "    getPositivePredictiveValue_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_ppv.bin\", \"ab+\") as f:\n",
    "    getPositivePredictiveValue_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_npv.bin\", \"ab+\") as f:\n",
    "    getNegativePredictiveValue_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_npv.bin\", \"ab+\") as f:\n",
    "    getNegativePredictiveValue_j(df).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"stat_parity.bin\", \"ab+\") as f:\n",
    "    get_statistical_parity(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"disp_impact.bin\", \"ab+\") as f:\n",
    "    get_disparate_impact(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"acc_equality_ratio.bin\", \"ab+\") as f:\n",
    "    get_acc_equality_ratio(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"acc_equality_diff.bin\", \"ab+\") as f:\n",
    "    get_acc_equality_diff(df).to_numpy().tofile(f)\n",
    "    \n",
    "del df\n",
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq72mH7zjkDo",
    "outputId": "3c68f020-7283-4b07-b1cb-a5f51d515ad7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -lah calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeeOR3sTjkDo"
   },
   "source": [
    "The files are written as `float64`, while the dataset has data-type `int8`, thus the size of each file is the same as the size of the dataset because each of them contains one 8 times heavier column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOT3O2yajkDp"
   },
   "source": [
    "# Get additional calculations\n",
    "These calculations will be based on the previous ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoYzFfdDjkDq"
   },
   "source": [
    "## Write 1st part\n",
    "Here the story is even worse as we need to open 2 files of the same size, so we will do it the same way: in 2 stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HURjnxCvoz20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"i_tpr.bin\", \"rb\") as f:\n",
    "    i_tpr = pd.DataFrame(np.fromfile(f), columns = [\"i_tpr\"])\n",
    "    halfIdx = int(i_tpr.shape[0] / 2)\n",
    "    i_tpr = i_tpr.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"j_tpr.bin\", \"rb\") as f:\n",
    "    j_tpr = pd.DataFrame(np.fromfile(f), columns = [\"j_tpr\"])\n",
    "    halfIdx = int(j_tpr.shape[0] / 2)\n",
    "    j_tpr = j_tpr.iloc[:halfIdx]\n",
    "    \n",
    "with open(calculationsDir + \"equal_opp_ratio.bin\", \"wb+\") as f:\n",
    "    get_equal_opp_ratio(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"equal_opp_diff.bin\", \"wb+\") as f:\n",
    "    get_equal_opp_diff(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "\n",
    "del j_tpr\n",
    "del i_tpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VBH3rVXMjkDt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"i_fpr.bin\", \"rb\") as f:\n",
    "    i_fpr = pd.DataFrame(np.fromfile(f), columns = [\"i_fpr\"])\n",
    "    halfIdx = int(i_fpr.shape[0] / 2)\n",
    "    i_fpr = i_fpr.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"j_fpr.bin\", \"rb\") as f:\n",
    "    j_fpr = pd.DataFrame(np.fromfile(f), columns = [\"j_fpr\"])\n",
    "    halfIdx = int(j_fpr.shape[0] / 2)\n",
    "    j_fpr = j_fpr.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"pred_equality_ratio.bin\", \"wb+\") as f:\n",
    "    get_pred_equality_ratio(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"pred_equality_diff.bin\", \"wb+\") as f:\n",
    "    get_pred_equality_diff(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "del j_fpr\n",
    "del i_fpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "whFb_KUEjkDu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"i_ppv.bin\", \"rb\") as f:\n",
    "    i_ppv = pd.DataFrame(np.fromfile(f), columns = [\"i_ppv\"])\n",
    "    halfIdx = int(i_ppv.shape[0] / 2)\n",
    "    i_ppv = i_ppv.iloc[:halfIdx]\n",
    "    \n",
    "with open(calculationsDir + \"j_ppv.bin\", \"rb\") as f:\n",
    "    j_ppv = pd.DataFrame(np.fromfile(f), columns = [\"j_ppv\"])\n",
    "    halfIdx = int(j_ppv.shape[0] / 2)\n",
    "    j_ppv = j_ppv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"pred_parity_ratio.bin\", \"wb+\") as f:\n",
    "    get_pred_parity_ratio(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"pos_pred_parity_diff.bin\", \"wb+\") as f:\n",
    "    get_pos_pred_parity_diff(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_ppv\n",
    "del i_ppv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_DKvl3w7jkDv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"i_npv.bin\", \"rb\") as f:\n",
    "    i_npv = pd.DataFrame(np.fromfile(f), columns = [\"i_npv\"])\n",
    "    halfIdx = int(i_npv.shape[0] / 2)\n",
    "    i_npv = i_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"j_npv.bin\", \"rb\") as f:\n",
    "    j_npv = pd.DataFrame(np.fromfile(f), columns = [\"j_npv\"])\n",
    "    halfIdx = int(j_npv.shape[0] / 2)\n",
    "    j_npv = j_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"neg_pred_parity_ratio.bin\", \"wb+\") as f:\n",
    "    get_neg_pred_parity_ratio(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"neg_pred_parity_diff.bin\", \"wb+\") as f:\n",
    "    get_neg_pred_parity_diff(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_npv\n",
    "del i_npv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRMFty8ajkDv"
   },
   "source": [
    "## Append 2nd part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Bx8lLzTajkDw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"i_tpr.bin\", \"rb\") as f:\n",
    "    i_tpr = pd.DataFrame(np.fromfile(f), columns = [\"i_tpr\"])\n",
    "    halfIdx = int(i_tpr.shape[0] / 2)\n",
    "    i_tpr = i_tpr.iloc[halfIdx:]\n",
    "\n",
    "with open(calculationsDir + \"j_tpr.bin\", \"rb\") as f:\n",
    "    j_tpr = pd.DataFrame(np.fromfile(f), columns = [\"j_tpr\"])\n",
    "    halfIdx = int(j_tpr.shape[0] / 2)\n",
    "    j_tpr = j_tpr.iloc[halfIdx:]\n",
    "    \n",
    "with open(calculationsDir + \"equal_opp_ratio.bin\", \"ab+\") as f:\n",
    "    get_equal_opp_ratio(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"equal_opp_diff.bin\", \"ab+\") as f:\n",
    "    get_equal_opp_diff(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "\n",
    "del j_tpr\n",
    "del i_tpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_IGQKxACjkDx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"i_fpr.bin\", \"rb\") as f:\n",
    "    i_fpr = pd.DataFrame(np.fromfile(f), columns = [\"i_fpr\"])\n",
    "    halfIdx = int(i_fpr.shape[0] / 2)\n",
    "    i_fpr = i_fpr.iloc[halfIdx:]\n",
    "\n",
    "with open(calculationsDir + \"j_fpr.bin\", \"rb\") as f:\n",
    "    j_fpr = pd.DataFrame(np.fromfile(f), columns = [\"j_fpr\"])\n",
    "    halfIdx = int(j_fpr.shape[0] / 2)\n",
    "    j_fpr = j_fpr.iloc[halfIdx:]\n",
    "\n",
    "with open(calculationsDir + \"pred_equality_ratio.bin\", \"ab+\") as f:\n",
    "    get_pred_equality_ratio(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"pred_equality_diff.bin\", \"ab+\") as f:\n",
    "    get_pred_equality_diff(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "del j_fpr\n",
    "del i_fpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2SHgiWRQjkDy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"i_ppv.bin\", \"rb\") as f:\n",
    "    i_ppv = pd.DataFrame(np.fromfile(f), columns = [\"i_ppv\"])\n",
    "    halfIdx = int(i_ppv.shape[0] / 2)\n",
    "    i_ppv = i_ppv.iloc[halfIdx:]\n",
    "    \n",
    "with open(calculationsDir + \"j_ppv.bin\", \"rb\") as f:\n",
    "    j_ppv = pd.DataFrame(np.fromfile(f), columns = [\"j_ppv\"])\n",
    "    halfIdx = int(j_ppv.shape[0] / 2)\n",
    "    j_ppv = j_ppv.iloc[halfIdx:]\n",
    "\n",
    "with open(calculationsDir + \"pred_parity_ratio.bin\", \"ab+\") as f:\n",
    "    get_pred_parity_ratio(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"pos_pred_parity_diff.bin\", \"ab+\") as f:\n",
    "    get_pos_pred_parity_diff(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_ppv\n",
    "del i_ppv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_BKX-a8CjkDz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"i_npv.bin\", \"rb\") as f:\n",
    "    i_npv = pd.DataFrame(np.fromfile(f), columns = [\"i_npv\"])\n",
    "    halfIdx = int(i_npv.shape[0] / 2)\n",
    "    i_npv = i_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"j_npv.bin\", \"rb\") as f:\n",
    "    j_npv = pd.DataFrame(np.fromfile(f), columns = [\"j_npv\"])\n",
    "    halfIdx = int(j_npv.shape[0] / 2)\n",
    "    j_npv = j_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"neg_pred_parity_ratio.bin\", \"ab+\") as f:\n",
    "    get_neg_pred_parity_ratio(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"neg_pred_parity_diff.bin\", \"ab+\") as f:\n",
    "    get_neg_pred_parity_diff(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_npv\n",
    "del i_npv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations for sonya plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sonya(df, base_metric):  \n",
    "    diff_metrics = {\n",
    "        'acc_equality_diff.bin': 'Accuracy equality difference', \n",
    "        'equal_opp_diff.bin': 'Equal opportunity difference', \n",
    "        'neg_pred_parity_diff.bin': 'Negative predictive parity difference', \n",
    "        'pos_pred_parity_diff.bin': 'Positive predictive parity difference', \n",
    "        'pred_equality_diff.bin': 'Predictive equality difference',\n",
    "        'stat_parity.bin': 'Statistical parity'\n",
    "    }\n",
    "    \n",
    "    diff_probs = {}\n",
    "    compute_diff_prob = lambda df: np.sum(df['diff'] == 0) / len(df)\n",
    "    \n",
    "    for metricFName in diff_metrics:\n",
    "        with open(calculationsDir + metricFName, \"rb\") as f:\n",
    "            diff_metric = pd.DataFrame(np.fromfile(f).astype(np.float16), columns = [\"diff\"])\n",
    "        df = pd.concat([df, diff_metric], axis = 1)\n",
    "\n",
    "        diff = df.groupby(base_metric).apply(compute_diff_prob)\n",
    "        diff_probs[diff_metrics[metricFName]] = diff\n",
    "\n",
    "        df.drop('diff', axis=1, inplace=True)\n",
    "        \n",
    "    sonya = pd.DataFrame(diff_probs)\n",
    "    sonya.reset_index(inplace=True)\n",
    "    sonya.to_csv(f\"{calculationsDir}sonya_xxxx\" + base_metric + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{calculationsDir}ir.bin\", \"rb\") as f:\n",
    "    df = pd.DataFrame(np.fromfile(f).astype(np.float16), columns = [\"ir\"])\n",
    "calculate_sonya(df, 'ir')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f011426f63b937df9084534402d60726e75436353eed0d60e767a35eaa72376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
