{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Shared calculations for histograms and perfect fairness, for all metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZvJFJUMJc-3"
   },
   "source": [
    "## Import libraries and define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "frbcDgnJ80wQ",
    "ExecuteTime": {
     "start_time": "2023-04-26T21:15:45.353511Z",
     "end_time": "2023-04-26T21:15:45.358401Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *  # metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N0C9QJbKjkDX",
    "ExecuteTime": {
     "start_time": "2023-04-26T21:15:45.354009Z",
     "end_time": "2023-04-26T21:15:45.360427Z"
    }
   },
   "outputs": [],
   "source": [
    "data_cols = [\n",
    "    'i_tp',     # minority true positive\n",
    "    'i_fp',     # minority false positive\n",
    "    'i_tn',     # minority true negative\n",
    "    'i_fn',     # minority false negative\n",
    "    'j_tp',     # majority true positive\n",
    "    'j_fp',     # majority false positive\n",
    "    'j_tn',     # majority true negative\n",
    "    'j_fn',     # majority false negative\n",
    "]\n",
    "\n",
    "sample_size = 56        # 56, 24\n",
    "\n",
    "calculations_dir = path.join('out', 'calculations', f'n{sample_size}')\n",
    "os.makedirs(calculations_dir, exist_ok=True)\n",
    "dataset_path = path.join('..', 'fairness-data-generator', 'out', f'Set(08,{sample_size}).bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SK8hWB3jkDY"
   },
   "source": [
    "# Get calculations\n",
    "As the dataset is quite large (4.2 Gb) we will write calculations to separate files in 2 stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3RXj2g1wILz"
   },
   "source": [
    "## Write calculations of the 1st half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bnGu5_3kaTaR",
    "outputId": "5acd9406-b43d-4784-ede3-f50fc60d8208",
    "ExecuteTime": {
     "start_time": "2023-04-26T21:15:49.517633Z",
     "end_time": "2023-04-26T21:15:53.250771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   i_tp  i_fp  i_tn  i_fn  j_tp  j_fp  j_tn  j_fn\n0    56     0     0     0     0     0     0     0\n1    55     1     0     0     0     0     0     0\n2    55     0     1     0     0     0     0     0\n3    55     0     0     1     0     0     0     0\n4    55     0     0     0     1     0     0     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>i_tp</th>\n      <th>i_fp</th>\n      <th>i_tn</th>\n      <th>i_fn</th>\n      <th>j_tp</th>\n      <th>j_fp</th>\n      <th>j_tn</th>\n      <th>j_fn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get half of the data\n",
    "with open(dataset_path, \"rb\") as f:\n",
    "    df = pd.DataFrame(pickle.load(f), columns=data_cols)\n",
    "\n",
    "halfIdx = df.shape[0] # // 2\n",
    "df = df.iloc[:halfIdx]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCq6NgtX7fye",
    "outputId": "a507ee6c-32ec-4e61-d0c4-fa7f6c46e88b",
    "ExecuteTime": {
     "start_time": "2023-04-26T21:15:53.248776Z",
     "end_time": "2023-04-26T21:15:53.324138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 553270671 entries, 0 to 553270670\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   i_tp    int8 \n",
      " 1   i_fp    int8 \n",
      " 2   i_tn    int8 \n",
      " 3   i_fn    int8 \n",
      " 4   j_tp    int8 \n",
      " 5   j_fp    int8 \n",
      " 6   j_tn    int8 \n",
      " 7   j_fn    int8 \n",
      "dtypes: int8(8)\n",
      "memory usage: 4.1 GB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2O6H_sXVlJFr",
    "outputId": "8c7b1a56-9887-415a-a14c-0fc566d555c8",
    "ExecuteTime": {
     "start_time": "2023-04-26T21:16:22.840098Z",
     "end_time": "2023-04-26T21:18:14.431342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'collections': 480, 'collected': 2514, 'uncollectable': 0},\n {'collections': 43, 'collected': 1115, 'uncollectable': 0},\n {'collections': 4, 'collected': 101, 'uncollectable': 0}]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate half of GRs\n",
    "with open(path.join(calculations_dir, \"gr.bin\"), \"wb+\") as f:\n",
    "    get_group_ratios(df).to_numpy().tofile(f)\n",
    "\n",
    "# Calculate half of IRs\n",
    "with open(path.join(calculations_dir, \"ir.bin\"), \"wb+\") as f:\n",
    "    get_imbalance_ratios(df).to_numpy().tofile(f)\n",
    "\n",
    "# calculate metrics\n",
    "with open(path.join(calculations_dir, \"i_tpr.bin\"), \"wb+\") as f:\n",
    "    getTPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_tpr.bin\"), \"wb+\") as f:\n",
    "    getTPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"i_fpr.bin\"), \"wb+\") as f:\n",
    "    getFPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_fpr.bin\"), \"wb+\") as f:\n",
    "    getFPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"i_ppv.bin\"), \"wb+\") as f:\n",
    "    get_positive_predictive_value_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_ppv.bin\"), \"wb+\") as f:\n",
    "    get_positive_predictive_value_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"i_npv.bin\"), \"wb+\") as f:\n",
    "    get_negative_predictive_value_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_npv.bin\"), \"wb+\") as f:\n",
    "    get_negative_predictive_value_j(df).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir, \"stat_parity.bin\"), \"wb+\") as f:\n",
    "    get_statistical_parity(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"disp_impact.bin\"), \"wb+\") as f:\n",
    "    get_disparate_impact(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"acc_equality_ratio.bin\"), \"wb+\") as f:\n",
    "    get_acc_equality_ratio(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"acc_equality_diff.bin\"), \"wb+\") as f:\n",
    "    get_acc_equality_diff(df).to_numpy().tofile(f)\n",
    "    \n",
    "# Free the memory\n",
    "del df\n",
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ1G6RB4wdby"
   },
   "source": [
    "## Append calculations of the 2st half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kYg-MGrluBpp",
    "ExecuteTime": {
     "start_time": "2023-04-26T20:54:28.523284Z",
     "end_time": "2023-04-26T20:54:28.539138Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(dataset_path, \"rb\") as f:\n",
    "    df = pd.DataFrame(pickle.load(f), columns=data_cols)\n",
    "\n",
    "# halfIdx = int(df.shape[0] / 2)\n",
    "df = df.iloc[halfIdx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZI6GFaih2eBR",
    "outputId": "3dfac9f1-d67b-42c4-f04a-10a7a860ffcd",
    "ExecuteTime": {
     "start_time": "2023-04-17T19:39:23.332182Z",
     "end_time": "2023-04-17T19:40:14.233577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'collections': 481, 'collected': 2469, 'uncollectable': 0},\n {'collections': 43, 'collected': 1115, 'uncollectable': 0},\n {'collections': 5, 'collected': 28, 'uncollectable': 0}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir, \"gr.bin\"), \"ab+\") as f:\n",
    "    get_group_ratios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"ir.bin\"), \"ab+\") as f:\n",
    "    get_imbalance_ratios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"i_tpr.bin\"), \"ab+\") as f:\n",
    "    getTPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_tpr.bin\"), \"ab+\") as f:\n",
    "    getTPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"i_fpr.bin\"), \"ab+\") as f:\n",
    "    getFPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_fpr.bin\"), \"ab+\") as f:\n",
    "    getFPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"i_ppv.bin\"), \"ab+\") as f:\n",
    "    get_positive_predictive_value_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_ppv.bin\"), \"ab+\") as f:\n",
    "    get_positive_predictive_value_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"i_npv.bin\"), \"ab+\") as f:\n",
    "    get_negative_predictive_value_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_npv.bin\"), \"ab+\") as f:\n",
    "    get_negative_predictive_value_j(df).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir, \"stat_parity.bin\"), \"ab+\") as f:\n",
    "    get_statistical_parity(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"disp_impact.bin\"), \"ab+\") as f:\n",
    "    get_disparate_impact(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"acc_equality_ratio.bin\"), \"ab+\") as f:\n",
    "    get_acc_equality_ratio(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"acc_equality_diff.bin\"), \"ab+\") as f:\n",
    "    get_acc_equality_diff(df).to_numpy().tofile(f)\n",
    "    \n",
    "del df\n",
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOT3O2yajkDp"
   },
   "source": [
    "# Get additional calculations\n",
    "These calculations will be based on the previous ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoYzFfdDjkDq"
   },
   "source": [
    "## Write 1st part\n",
    "Here the story is even worse as we need to open 2 files of the same size, so we will do it the same way: in 2 stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HURjnxCvoz20",
    "ExecuteTime": {
     "start_time": "2023-04-26T21:18:30.559169Z",
     "end_time": "2023-04-26T21:18:56.783050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir, \"i_tpr.bin\"), \"rb\") as f:\n",
    "    i_tpr = pd.DataFrame(np.fromfile(f), columns=[\"i_tpr\"])\n",
    "    # halfIdx = int(i_tpr.shape[0] / 2)\n",
    "    i_tpr = i_tpr.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_tpr.bin\"), \"rb\") as f:\n",
    "    j_tpr = pd.DataFrame(np.fromfile(f), columns=[\"j_tpr\"])\n",
    "    # halfIdx = int(j_tpr.shape[0] / 2)\n",
    "    j_tpr = j_tpr.iloc[:halfIdx]\n",
    "    \n",
    "with open(path.join(calculations_dir, \"equal_opp_ratio.bin\"), \"wb+\") as f:\n",
    "    get_equal_opp_ratio(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir, \"equal_opp_diff.bin\"), \"wb+\") as f:\n",
    "    get_equal_opp_diff(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "\n",
    "del j_tpr\n",
    "del i_tpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VBH3rVXMjkDt",
    "ExecuteTime": {
     "start_time": "2023-04-26T21:18:56.784460Z",
     "end_time": "2023-04-26T21:19:24.701879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir, \"i_fpr.bin\"), \"rb\") as f:\n",
    "    i_fpr = pd.DataFrame(np.fromfile(f), columns=[\"i_fpr\"])\n",
    "    # halfIdx = int(i_fpr.shape[0] / 2)\n",
    "    i_fpr = i_fpr.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_fpr.bin\"), \"rb\") as f:\n",
    "    j_fpr = pd.DataFrame(np.fromfile(f), columns=[\"j_fpr\"])\n",
    "    # halfIdx = int(j_fpr.shape[0] / 2)\n",
    "    j_fpr = j_fpr.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir, \"pred_equality_ratio.bin\"), \"wb+\") as f:\n",
    "    get_pred_equality_ratio(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir, \"pred_equality_diff.bin\"), \"wb+\") as f:\n",
    "    get_pred_equality_diff(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "del j_fpr\n",
    "del i_fpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "whFb_KUEjkDu",
    "ExecuteTime": {
     "start_time": "2023-04-26T21:19:24.688089Z",
     "end_time": "2023-04-26T21:19:50.668961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir, \"i_ppv.bin\"), \"rb\") as f:\n",
    "    i_ppv = pd.DataFrame(np.fromfile(f), columns=[\"i_ppv\"])\n",
    "    # halfIdx = int(i_ppv.shape[0] / 2)\n",
    "    i_ppv = i_ppv.iloc[:halfIdx]\n",
    "    \n",
    "with open(path.join(calculations_dir, \"j_ppv.bin\"), \"rb\") as f:\n",
    "    j_ppv = pd.DataFrame(np.fromfile(f), columns=[\"j_ppv\"])\n",
    "    # halfIdx = int(j_ppv.shape[0] / 2)\n",
    "    j_ppv = j_ppv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir, \"pos_pred_parity_ratio.bin\"), \"wb+\") as f:\n",
    "    get_pos_pred_parity_ratio(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"pos_pred_parity_diff.bin\"), \"wb+\") as f:\n",
    "    get_pos_pred_parity_diff(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_ppv\n",
    "del i_ppv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_DKvl3w7jkDv",
    "ExecuteTime": {
     "start_time": "2023-04-26T21:19:51.156645Z",
     "end_time": "2023-04-26T21:20:16.092785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir, \"i_npv.bin\"), \"rb\") as f:\n",
    "    i_npv = pd.DataFrame(np.fromfile(f), columns=[\"i_npv\"])\n",
    "    # halfIdx = int(i_npv.shape[0] / 2)\n",
    "    i_npv = i_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_npv.bin\"), \"rb\") as f:\n",
    "    j_npv = pd.DataFrame(np.fromfile(f), columns=[\"j_npv\"])\n",
    "    # halfIdx = int(j_npv.shape[0] / 2)\n",
    "    j_npv = j_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir, \"neg_pred_parity_ratio.bin\"), \"wb+\") as f:\n",
    "    get_neg_pred_parity_ratio(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"neg_pred_parity_diff.bin\"), \"wb+\") as f:\n",
    "    get_neg_pred_parity_diff(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_npv\n",
    "del i_npv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRMFty8ajkDv"
   },
   "source": [
    "## Append 2nd part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Bx8lLzTajkDw",
    "ExecuteTime": {
     "start_time": "2023-04-17T19:41:40.147688Z",
     "end_time": "2023-04-17T19:41:56.771558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir, \"i_tpr.bin\"), \"rb\") as f:\n",
    "    i_tpr = pd.DataFrame(np.fromfile(f), columns=[\"i_tpr\"])\n",
    "    # halfIdx = int(i_tpr.shape[0] / 2)\n",
    "    i_tpr = i_tpr.iloc[halfIdx:]\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_tpr.bin\"), \"rb\") as f:\n",
    "    j_tpr = pd.DataFrame(np.fromfile(f), columns=[\"j_tpr\"])\n",
    "    # halfIdx = int(j_tpr.shape[0] / 2)\n",
    "    j_tpr = j_tpr.iloc[halfIdx:]\n",
    "    \n",
    "with open(path.join(calculations_dir, \"equal_opp_ratio.bin\"), \"ab+\") as f:\n",
    "    get_equal_opp_ratio(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir, \"equal_opp_diff.bin\"), \"ab+\") as f:\n",
    "    get_equal_opp_diff(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "\n",
    "del j_tpr\n",
    "del i_tpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_IGQKxACjkDx",
    "ExecuteTime": {
     "start_time": "2023-04-17T19:41:56.765242Z",
     "end_time": "2023-04-17T19:42:11.339463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir, \"i_fpr.bin\"), \"rb\") as f:\n",
    "    i_fpr = pd.DataFrame(np.fromfile(f), columns=[\"i_fpr\"])\n",
    "    # halfIdx = int(i_fpr.shape[0] / 2)\n",
    "    i_fpr = i_fpr.iloc[halfIdx:]\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_fpr.bin\"), \"rb\") as f:\n",
    "    j_fpr = pd.DataFrame(np.fromfile(f), columns=[\"j_fpr\"])\n",
    "    # halfIdx = int(j_fpr.shape[0] / 2)\n",
    "    j_fpr = j_fpr.iloc[halfIdx:]\n",
    "\n",
    "with open(path.join(calculations_dir, \"pred_equality_ratio.bin\"), \"ab+\") as f:\n",
    "    get_pred_equality_ratio(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(path.join(calculations_dir, \"pred_equality_diff.bin\"), \"ab+\") as f:\n",
    "    get_pred_equality_diff(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "del j_fpr\n",
    "del i_fpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2SHgiWRQjkDy",
    "ExecuteTime": {
     "start_time": "2023-04-17T19:42:11.337077Z",
     "end_time": "2023-04-17T19:42:31.508233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir, \"i_ppv.bin\"), \"rb\") as f:\n",
    "    i_ppv = pd.DataFrame(np.fromfile(f), columns=[\"i_ppv\"])\n",
    "    # halfIdx = int(i_ppv.shape[0] / 2)\n",
    "    i_ppv = i_ppv.iloc[halfIdx:]\n",
    "    \n",
    "with open(path.join(calculations_dir, \"j_ppv.bin\"), \"rb\") as f:\n",
    "    j_ppv = pd.DataFrame(np.fromfile(f), columns=[\"j_ppv\"])\n",
    "    # halfIdx = int(j_ppv.shape[0] / 2)\n",
    "    j_ppv = j_ppv.iloc[halfIdx:]\n",
    "\n",
    "with open(path.join(calculations_dir, \"pos_pred_parity_ratio.bin\"), \"ab+\") as f:\n",
    "    get_pos_pred_parity_ratio(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"pos_pred_parity_diff.bin\"), \"ab+\") as f:\n",
    "    get_pos_pred_parity_diff(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_ppv\n",
    "del i_ppv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path.join(calculations_dir, \"i_npv.bin\"), \"rb\") as f:\n",
    "    i_npv = pd.DataFrame(np.fromfile(f), columns=[\"i_npv\"])\n",
    "    # halfIdx = int(i_npv.shape[0] / 2)\n",
    "    i_npv = i_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir, \"j_npv.bin\"), \"rb\") as f:\n",
    "    j_npv = pd.DataFrame(np.fromfile(f), columns=[\"j_npv\"])\n",
    "    # halfIdx = int(j_npv.shape[0] / 2)\n",
    "    j_npv = j_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(path.join(calculations_dir, \"neg_pred_parity_ratio.bin\"), \"ab+\") as f:\n",
    "    get_neg_pred_parity_ratio(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(path.join(calculations_dir, \"neg_pred_parity_diff.bin\"), \"ab+\") as f:\n",
    "    get_neg_pred_parity_diff(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_npv\n",
    "del i_npv\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f011426f63b937df9084534402d60726e75436353eed0d60e767a35eaa72376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
