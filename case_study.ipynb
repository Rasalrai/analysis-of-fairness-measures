{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adult Dataset, aka Census income\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/adult"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "plt.style.use('default')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:51:26.976176Z",
     "end_time": "2023-05-03T14:51:26.981170Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:09:26.740110Z",
     "end_time": "2023-05-03T13:09:26.740363Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23162/1575989903.py:17: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dataset = pd.read_csv('data/adult.data', sep=', ', na_values=['?', ' ?'],\n"
     ]
    },
    {
     "data": {
      "text/plain": "   age         workclass  education  education-num      marital-status  \\\n0   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n1   38           Private    HS-grad              9            Divorced   \n2   53           Private       11th              7  Married-civ-spouse   \n3   28           Private  Bachelors             13  Married-civ-spouse   \n4   37           Private    Masters             14  Married-civ-spouse   \n\n          occupation   relationship   race     sex  capital-gain  \\\n0    Exec-managerial        Husband  White    Male             0   \n1  Handlers-cleaners  Not-in-family  White    Male             0   \n2  Handlers-cleaners        Husband  Black    Male             0   \n3     Prof-specialty           Wife  Black  Female             0   \n4    Exec-managerial           Wife  White  Female             0   \n\n   capital-loss  hours-per-week native-country income  \n0             0              13  United-States  <=50K  \n1             0              40  United-States  <=50K  \n2             0              40  United-States  <=50K  \n3             0              40           Cuba  <=50K  \n4             0              40  United-States  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37</td>\n      <td>Private</td>\n      <td>Masters</td>\n      <td>14</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',       # removed\n",
    "    'education',    # sorted later on\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "]\n",
    "dataset = pd.read_csv('data/adult.data', sep=', ', na_values=['?', ' ?'],\n",
    "                      header=0, names=features + ['income'])\n",
    "dataset.drop(columns=['fnlwgt'], inplace=True)\n",
    "features.remove('fnlwgt')\n",
    "\n",
    "plots_dir = os.path.join('out', 'plots', 'case_study', 'census_income')\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Group and class sizes\n",
    "\n",
    "groups: sex\n",
    "class: income (1: >=50k)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32560, 14)\n",
      "10771\n",
      "21789\n",
      "24719\n",
      "7841\n",
      "\n",
      "\n",
      "\n",
      "F 0: 9592\n",
      "F 1: 1179\n",
      "M 0: 15127\n",
      "M 1: 6662\n"
     ]
    }
   ],
   "source": [
    "# decide on the split size\n",
    "\n",
    "print(\n",
    "    dataset.shape,\n",
    "    dataset[dataset['sex'] == 'Female'].shape[0],\n",
    "    dataset[dataset['sex'] != 'Female'].shape[0],\n",
    "    dataset[dataset['income'] != '>50K'].shape[0],\n",
    "    dataset[dataset['income'] == '>50K'].shape[0],\n",
    "    # dataset[(dataset['income'] == '>50K') & (dataset['sex'] == 'Female')].shape,\n",
    "    sep='\\n'\n",
    ")\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# check set intersections\n",
    "conditions_g = [\n",
    "    (dataset['sex'] == 'Female', 'F'),\n",
    "    (dataset['sex'] == 'Male', 'M'),\n",
    "]\n",
    "\n",
    "conditions_i = [\n",
    "    (dataset['income'] == '<=50K', '0'),\n",
    "    (dataset['income'] == '>50K', '1'),\n",
    "]\n",
    "\n",
    "for c_g, g in conditions_g:\n",
    "    for c_i, i in conditions_i:\n",
    "        print(f'{g} {i}: {dataset[c_g & c_i].shape[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:09:43.827667Z",
     "end_time": "2023-05-03T13:09:43.827896Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## different approaches for creating subsets\n",
    "\n",
    "### split approach 1: \"ladies first\"\n",
    "1. sample the needed number of women\n",
    "1. calculate the number of rows of each class that we got in this way, and replace if there's too many of one class\n",
    "1. calculate how many men of each class we need to get the desired ratio\n",
    "1. sample the men (separately for each class) and join all the selected samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# [majority, minority]\n",
    "sex = ['Male', 'Female']\n",
    "income = ['<=50K', '>50K']\n",
    "\n",
    "def split_03(dset, n, gr, ir):\n",
    "    cls_n = [int(n * (1 - ir)), int(n * ir)]\n",
    "    sex_n = [int(n * (1 - gr)), int(n * gr)]\n",
    "\n",
    "    # decide ratio of poor/rich women, based on the ratio from original data\n",
    "    og0 = dset[(dset['sex'] == sex[1]) & (dset['income'] == income[0])].shape[0] / dset[dset['sex'] == sex[1]].shape[0]\n",
    "    # og1 = dset[(dset['sex'] == sex[1]) & (dset['income'] == income[1])].shape[0] / dset.shape[0]\n",
    "    print(og0)\n",
    "\n",
    "    f0 = round(sex_n[1] * og0)\n",
    "    f1 = sex_n[1] - f0\n",
    "    print('f: ', f0, f1)\n",
    "\n",
    "    # sample women\n",
    "    df = pd.concat([\n",
    "        dset[(dset['sex'] == sex[1]) & (dset['income'] == income[0])].sample(n=f0, random_state=2137),\n",
    "        dset[(dset['sex'] == sex[1]) & (dset['income'] == income[1])].sample(n=f1, random_state=2137),\n",
    "    ])\n",
    "    print('f: ', f0, f1)\n",
    "    assert f0 + f1 == sex_n[1]\n",
    "\n",
    "    # sample men\n",
    "    m0 = cls_n[0] - f0\n",
    "    m1 = cls_n[1] - f1\n",
    "    print(\"m: \", m0, m1)\n",
    "    assert m0 + m1 == sex_n[0]\n",
    "\n",
    "    df_m0 = dset[\n",
    "        (dset['sex'] == sex[0]) & (dset['income'] == income[0])\n",
    "        ].sample(n=m0, random_state=2137)\n",
    "    df_m1 = dset[\n",
    "        (dset['sex'] == sex[0]) & (dset['income'] == income[1])\n",
    "        ].sample(n=m1, random_state=2137)\n",
    "\n",
    "    # print(df_m0.shape, df_m1.shape)\n",
    "    df = pd.concat([df, df_m0, df_m1])\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:09:49.459490Z",
     "end_time": "2023-05-03T13:09:49.459704Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### split approach 2: set ratios in advance\n",
    "\n",
    "1. decide on number of f0, f1, m0, m1\n",
    "2. sample accordingly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "n = dataset.shape[0]\n",
    "gr = ir = .5\n",
    "\n",
    "# [majority, minority]\n",
    "sex = ['Male', 'Female']\n",
    "income = ['<=50K', '>50K']\n",
    "\n",
    "\n",
    "def split_02(df, n, gr, ir, group_swap=False, cls_swap=False):\n",
    "    \"\"\"\n",
    "    :param df: original data\n",
    "    :param n: final size of the sample\n",
    "    :param cls_swap: if you want to swap the groups (i.e. get `gr` men and not women)\n",
    "    :param group_swap: if want to swap the decision classes (i.e. get `ir`of the poor and not the rich)\n",
    "    :return: the sample\n",
    "    \"\"\"\n",
    "    data_len = df.shape[0]\n",
    "    # set ratios of sex and income\n",
    "    f0 = round(n * gr * (1 - ir))\n",
    "    f1 = round(n * gr * ir)\n",
    "    m0 = round(n * (1 - gr) * (1 - ir))\n",
    "    m1 = round(n * (1 - gr) * ir)\n",
    "\n",
    "    if group_swap:\n",
    "        f0, f1, m0, m1 = m0, m1, f0, f1\n",
    "    if cls_swap:\n",
    "        f0, f1, m0, m1 = f1, f0, m1, m0\n",
    "    print(f0, f1, m0, m1)\n",
    "\n",
    "    sample = pd.concat([\n",
    "        df[(df['sex'] == sex[1]) & (df['income'] == income[0])].sample(n=int(f0), random_state=2137),\n",
    "        df[(df['sex'] == sex[1]) & (df['income'] == income[1])].sample(n=int(f1), random_state=2137),\n",
    "        df[(df['sex'] == sex[0]) & (df['income'] == income[0])].sample(n=int(m0), random_state=2137),\n",
    "        df[(df['sex'] == sex[0]) & (df['income'] == income[1])].sample(n=int(m1), random_state=2137),\n",
    "    ]).reset_index(drop=True)\n",
    "    return sample\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:09:51.111637Z",
     "end_time": "2023-05-03T13:09:51.111977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def split_04(dset, n, gr, ir):\n",
    "    cls_n = [int(n * (1 - ir)), int(n * ir)]\n",
    "    sex_n = [int(n * (1 - gr)), int(n * gr)]\n",
    "    print('cls: ', cls_n)\n",
    "    print('sex: ', sex_n)\n",
    "\n",
    "    f1_max = min(cls_n[0], sex_n[1], dset[(dset['sex'] == sex[1]) & (dset['income'] == income[1])].shape[0])\n",
    "    f1 = round(min(\n",
    "        np.random.normal(f1_max / 2, f1_max / 5),\n",
    "        f1_max,\n",
    "        cls_n[1],\n",
    "        sex_n[1],\n",
    "    ) * .9)\n",
    "    f0 = sex_n[1] - f1\n",
    "    m0 = cls_n[0] - f0\n",
    "    m1 = sex_n[0] - m0\n",
    "\n",
    "    print(f0, f1, m0, m1)\n",
    "\n",
    "    sample = pd.concat([\n",
    "        dset[(dset['sex'] == sex[1]) & (dset['income'] == income[0])].sample(n=int(f0), random_state=2137),\n",
    "        dset[(dset['sex'] == sex[1]) & (dset['income'] == income[1])].sample(n=int(f1), random_state=2137),\n",
    "        dset[(dset['sex'] == sex[0]) & (dset['income'] == income[0])].sample(n=int(m0), random_state=2137),\n",
    "        dset[(dset['sex'] == sex[0]) & (dset['income'] == income[1])].sample(n=int(m1), random_state=2137),\n",
    "    ]).reset_index(drop=True)\n",
    "    return sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:09:51.936668Z",
     "end_time": "2023-05-03T13:09:51.936948Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## preprocessing and helpers for classification/evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "categorical_fs = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "]\n",
    "\n",
    "education_order = [\n",
    "    'Preschool',\n",
    "    '1st-4th',\n",
    "    '5th-6th',\n",
    "    '7th-8th',\n",
    "    '9th',\n",
    "    '10th',\n",
    "    '11th',\n",
    "    '12th',\n",
    "    'HS-grad',\n",
    "    'Some-college',\n",
    "    'Assoc-acdm',\n",
    "    'Assoc-voc',\n",
    "    'Bachelors',\n",
    "    'Masters',\n",
    "    'Prof-school',\n",
    "    'Doctorate',\n",
    "]\n",
    "\n",
    "# get the columns in the correct order\n",
    "cols = np.concatenate([dataset.columns.copy(deep=True).drop(categorical_fs + ['income']), categorical_fs])\n",
    "cols_d = {c: i for i, c in enumerate(cols)}\n",
    "\n",
    "classifiers = [\n",
    "    [RandomForestClassifier, {'random_state': 2137}],\n",
    "    [DecisionTreeClassifier, {'random_state': 2137}],\n",
    "    [GaussianNB, {}],\n",
    "    [LogisticRegression, {}],\n",
    "    [KNeighborsClassifier, {}],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:09:53.211961Z",
     "end_time": "2023-05-03T13:09:53.212199Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    X_all = dataset[features]\n",
    "    y_all = LabelEncoder().fit_transform(dataset['income'])\n",
    "\n",
    "    # encode categorical features\n",
    "    data_encoder = OrdinalEncoder().fit(X_all[categorical_fs])\n",
    "    X_categorical = data_encoder.transform(X_all[categorical_fs])\n",
    "\n",
    "    edu_encoder = OrdinalEncoder(categories=[education_order]).fit(X_all[['education']])\n",
    "    X_categorical[:, categorical_fs.index('education')] = edu_encoder.transform(X_all[['education']])[0]\n",
    "\n",
    "    # finally, the features\n",
    "    X_all = np.concatenate([X_all.drop(categorical_fs, axis=1), X_categorical], axis=1)\n",
    "    # X_all[:5]\n",
    "\n",
    "    return X_all, y_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:09:53.712480Z",
     "end_time": "2023-05-03T13:09:53.712868Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def calculate_fairness(clf, X, y, protected, group=1, cls=1):\n",
    "    \"\"\"\n",
    "    :param protected: id/name of the protected attribute column\n",
    "    :param group: id of the protected group\n",
    "    :param cls: id of the positive class\n",
    "    :return: dictionary of fairness metrics for the given classifier's results\n",
    "    \"\"\"\n",
    "    y_pred = clf.predict(X)\n",
    "    # columns: protected_value, y_true, y_pred\n",
    "    labelled = np.concatenate([\n",
    "        X[:, protected].reshape(-1, 1),\n",
    "        y.reshape(-1, 1),\n",
    "        y_pred.reshape(-1, 1)\n",
    "    ], axis=1)\n",
    "\n",
    "    # calculate confusion matrices\n",
    "    cms = [None, None]\n",
    "\n",
    "    # y true/pred for the protected group\n",
    "    ys = labelled[labelled[:, 0] == group]\n",
    "    cms[0] = confusion_matrix(ys[:, 1], ys[:, 2], labels=[0, 1])\n",
    "    # ... and for the other (unprotected) group\n",
    "    ys = labelled[labelled[:, 0] != group]\n",
    "    cms[1] = confusion_matrix(ys[:, 1], ys[:, 2], labels=[0, 1])\n",
    "\n",
    "    # print(*cms, sep='\\n')\n",
    "\n",
    "    # mj = majority - unprotected\n",
    "    # mr = minority - protected\n",
    "    mr, mj = group, 1 - group\n",
    "    pos, neg = cls, 1 - cls\n",
    "\n",
    "    # labels for the confusion matrix items\n",
    "    tn = (neg, neg)\n",
    "    fp = (neg, pos)\n",
    "    fn = (pos, neg)\n",
    "    tp = (pos, pos)\n",
    "\n",
    "    # calculate fairness metrics\n",
    "    fairness = dict()\n",
    "\n",
    "    # Accuracy Equality Difference\n",
    "    fairness['Accuracy Equality Difference'] = \\\n",
    "        (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
    "        (cms[mr].item(tp) + cms[mr].item(tn)) / cms[mr].sum()\n",
    "\n",
    "    # Equal Opportunity Difference: j_tpr - i_tpr\n",
    "    try:\n",
    "        fairness['Equal Opportunity Difference'] = \\\n",
    "            cms[mj].item(tp) / (cms[mj].item(tp) + cms[mj].item(fn)) - \\\n",
    "            cms[mr].item(tp) / (cms[mr].item(tp) + cms[mr].item(fn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Equal Opportunity Difference'] = np.nan\n",
    "\n",
    "    # Predictive Equality Difference: j_fpr - i_fpr\n",
    "    try:\n",
    "        fairness['Predictive Equality Difference'] = \\\n",
    "            cms[mj].item(fp) / (cms[mj].item(fp) + cms[mj].item(tn)) - \\\n",
    "            cms[mr].item(fp) / (cms[mr].item(fp) + cms[mr].item(tn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Predictive Equality Difference'] = np.nan\n",
    "\n",
    "    # Positive Predictive Parity Difference: j_ppv - i_ppv\n",
    "    try:\n",
    "        fairness['Positive Predictive Parity Difference'] = \\\n",
    "            cms[mj].item(tp) / (cms[mj].item(tp) + cms[mj].item(fp)) - \\\n",
    "            cms[mr].item(tp) / (cms[mr].item(tp) + cms[mr].item(fp))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Positive Predictive Parity Difference'] = np.nan\n",
    "\n",
    "    # Negative Predictive Parity Difference: j_npv - i_npv\n",
    "    try:\n",
    "        fairness['Negative Predictive Parity Difference'] = \\\n",
    "            cms[mj].item(tn) / (cms[mj].item(tn) + cms[mj].item(fn)) - \\\n",
    "            cms[mr].item(tn) / (cms[mr].item(tn) + cms[mr].item(fn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Negative Predictive Parity Difference'] = np.nan\n",
    "\n",
    "    fairness['Statistical Parity Difference'] = \\\n",
    "        (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
    "        (cms[mr].item(tp) + cms[mr].item(fp)) / cms[mr].sum()\n",
    "\n",
    "    return fairness"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:09:54.161974Z",
     "end_time": "2023-05-03T13:09:54.162246Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# 'vibrant' scheme from https://personal.sron.nl/~pault/\n",
    "colours = ['#EE7733', '#0077BB', '#33BBEE', '#EE3377', '#CC3311', '#009988']\n",
    "\n",
    "# group by metric\n",
    "def plot_fairness_gb_metric(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = ['\\n'.join([' '.join(f.split(\" \")[:2]), ' '.join(f.split(\" \")[2:])])\n",
    "               for f in fairness[list(fairness.keys())[0]].keys()]\n",
    "    xticks = np.arange(len(metrics))\n",
    "    width = 1. / (len(fairness.keys()) + 2)\n",
    "\n",
    "    for i, (clf, f) in enumerate(fairness.items()):\n",
    "        ax.bar(xticks + i * width, f.values(), width, label=clf.replace('Classifier', ''), color=colours[i])\n",
    "\n",
    "    ax.set_xticks(xticks + width * len(fairness.keys()) / 2, metrics, rotation=45)\n",
    "    ax.legend(ncols=1)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_fairness_gb_clf(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = fairness[list(fairness.keys())[0]].keys()\n",
    "    classifiers = [c.replace('Classifier', '') for c in fairness.keys()]\n",
    "    xticks = np.arange(len(classifiers))\n",
    "    width = 1. / (len(metrics) + 2)\n",
    "    shift = np.arange(len(metrics)) * width\n",
    "\n",
    "    for i, (clf, f) in enumerate(fairness.items()):\n",
    "        ax.bar(i + shift, f.values(), width, color=colours[:len(metrics)])\n",
    "    # ax.bar(xticks + shift, fairness, width)\n",
    "    ax.set_xticks(xticks + width * len(metrics) / 2, classifiers)\n",
    "    ax.legend(handles=[mpatches.Patch(color=c, label=m) for c, m in zip(colours, metrics)], ncol=1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:35:22.598571Z",
     "end_time": "2023-05-03T13:35:22.598706Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Line graph: `fairness(ratio)`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "# cv = RepeatedKFold(n_splits=2, n_repeats=15, random_state=2137)    # 30 splits\n",
    "holdout = ShuffleSplit(n_splits=50, test_size=.33, random_state=2137)\n",
    "SAMPLE_SIZE = 1100\n",
    "split = split_02\n",
    "\n",
    "rs = [.01, .02, .05] + [round(x, 2) for x in np.arange(.1, 1., .1)] + [.95, .98, .99]\n",
    "# rs = [.02, .05] + [round(x, 2) for x in np.arange(.1, 1., .1)] + [.95, .98]\n",
    "ratios = [[.5, ir] for ir in rs] + [[gr, .5] for gr in rs]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:10:19.551225Z",
     "end_time": "2023-05-03T13:10:19.551402Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GR: 0.5, IR: 0.01\n",
      "544 6 544 6\n",
      "GR: 0.5, IR: 0.02\n",
      "539 11 539 11\n",
      "GR: 0.5, IR: 0.05\n",
      "522 28 522 28\n",
      "GR: 0.5, IR: 0.1\n",
      "495 55 495 55\n",
      "GR: 0.5, IR: 0.2\n",
      "440 110 440 110\n",
      "GR: 0.5, IR: 0.3\n",
      "385 165 385 165\n",
      "GR: 0.5, IR: 0.4\n",
      "330 220 330 220\n",
      "GR: 0.5, IR: 0.5\n",
      "275 275 275 275\n",
      "GR: 0.5, IR: 0.6\n",
      "220 330 220 330\n",
      "GR: 0.5, IR: 0.7\n",
      "165 385 165 385\n",
      "GR: 0.5, IR: 0.8\n",
      "110 440 110 440\n",
      "GR: 0.5, IR: 0.9\n",
      "55 495 55 495\n",
      "GR: 0.5, IR: 0.95\n",
      "28 522 28 522\n",
      "GR: 0.5, IR: 0.98\n",
      "11 539 11 539\n",
      "GR: 0.5, IR: 0.99\n",
      "6 544 6 544\n",
      "GR: 0.01, IR: 0.5\n",
      "6 6 544 544\n",
      "GR: 0.02, IR: 0.5\n",
      "11 11 539 539\n",
      "GR: 0.05, IR: 0.5\n",
      "28 28 522 522\n",
      "GR: 0.1, IR: 0.5\n",
      "55 55 495 495\n",
      "GR: 0.2, IR: 0.5\n",
      "110 110 440 440\n",
      "GR: 0.3, IR: 0.5\n",
      "165 165 385 385\n",
      "GR: 0.4, IR: 0.5\n",
      "220 220 330 330\n",
      "GR: 0.5, IR: 0.5\n",
      "275 275 275 275\n",
      "GR: 0.6, IR: 0.5\n",
      "330 330 220 220\n",
      "GR: 0.7, IR: 0.5\n",
      "385 385 165 165\n",
      "GR: 0.8, IR: 0.5\n",
      "440 440 110 110\n",
      "GR: 0.9, IR: 0.5\n",
      "495 495 55 55\n",
      "GR: 0.95, IR: 0.5\n",
      "522 522 28 28\n",
      "GR: 0.98, IR: 0.5\n",
      "539 539 11 11\n",
      "GR: 0.99, IR: 0.5\n",
      "544 544 6 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23162/1955643229.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_23162/1955643229.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_23162/1955643229.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_23162/1955643229.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_23162/1955643229.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_23162/1955643229.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_23162/1955643229.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_23162/1955643229.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_23162/1955643229.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_23162/1955643229.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n"
     ]
    }
   ],
   "source": [
    "# calculations\n",
    "# fairness_results_cv = {}\n",
    "results = []\n",
    "\n",
    "for gr, ir in ratios:\n",
    "# for gr, ir in [[.5, .9], [.5, .01]]:\n",
    "    print(f'GR: {gr}, IR: {ir}')\n",
    "\n",
    "    # because we don't have enough rich women in the dataset\n",
    "    # swap_gr = True if gr > .5 else False\n",
    "    # swap_ir = True if ir > .5 else False\n",
    "    swap_gr, swap_ir = False, False\n",
    "\n",
    "    df = split(dataset, SAMPLE_SIZE, gr, ir, group_swap=swap_gr, cls_swap=swap_ir)\n",
    "    X_all, y_all = preprocess(df)\n",
    "\n",
    "    for i, (traini, testi) in enumerate(holdout.split(X_all)):\n",
    "        X_train, X_test = X_all[traini], X_all[testi]\n",
    "        y_train, y_test = y_all[traini], y_all[testi]\n",
    "\n",
    "        for clf, kwargs in classifiers:\n",
    "            pipe = make_pipeline(\n",
    "                KNNImputer(),\n",
    "                StandardScaler(),\n",
    "                clf(**kwargs)\n",
    "            ).fit(X_train, y_train)\n",
    "            f = calculate_fairness(pipe, X_test, y_test, cols_d['sex'], group=1-int(swap_gr), cls=1-int(swap_ir))\n",
    "\n",
    "            for metric, value in f.items():\n",
    "                results.append([gr, ir, clf.__name__.replace('Classifier', ''), metric, value])\n",
    "\n",
    "fairness_results_cv = pd.DataFrame(results, columns=['gr', 'ir', 'clf', 'metric', 'value'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:21:15.896907Z",
     "end_time": "2023-05-03T13:21:15.897502Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "    gr    ir           clf                                 metric     value\n0  0.5  0.01  RandomForest           Accuracy Equality Difference -0.011846\n1  0.5  0.01  RandomForest           Equal Opportunity Difference  0.000000\n2  0.5  0.01  RandomForest         Predictive Equality Difference  0.000000\n3  0.5  0.01  RandomForest  Positive Predictive Parity Difference       NaN\n4  0.5  0.01  RandomForest  Negative Predictive Parity Difference -0.011846",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gr</th>\n      <th>ir</th>\n      <th>clf</th>\n      <th>metric</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Accuracy Equality Difference</td>\n      <td>-0.011846</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Equal Opportunity Difference</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Predictive Equality Difference</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Positive Predictive Parity Difference</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Negative Predictive Parity Difference</td>\n      <td>-0.011846</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_results_cv.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:21:16.001151Z",
     "end_time": "2023-05-03T13:21:16.001411Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def plot_line(fairness: pd.DataFrame, metric: str, ratio_type: str, fill='std', ylim=(-.5, .5)):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # ax.set_title(f'Value of *{metric}* for different {ratio_type.upper()}')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(ratio_type.upper())\n",
    "\n",
    "    metrics = fairness['metric'].unique()\n",
    "    clfs = fairness['clf'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "    mean, stdev, err = {}, {}, {}\n",
    "\n",
    "    for r in ratios:\n",
    "        for clf in clfs:\n",
    "            subset = fairness[\n",
    "                (fairness[ratio_type] == r) &\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric) &\n",
    "                fairness['value'].notna()\n",
    "            ]\n",
    "            mean[(r, clf)] = subset['value'].mean(skipna=True)\n",
    "            stdev[(r, clf)] = subset['value'].std(skipna=True)\n",
    "            err[(r, clf)] = scipy.stats.sem(subset['value'], nan_policy='omit')\n",
    "\n",
    "    ax.axhline(0, color='black', linestyle='--', alpha=.3)\n",
    "\n",
    "    for i, clf in enumerate(clfs):\n",
    "        ax.plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[i], marker='o')\n",
    "        if fill == 'err':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "        elif fill == 'std':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "\n",
    "    # if (metric == 'Negative Predictive Parity Difference' and ratio_type == 'ir') or \\\n",
    "    #     (metric == 'Statistical Parity Difference' and ratio_type == 'gr') or \\\n",
    "    #     metric == 'Predictive Equality Difference':\n",
    "    #     ax.legend(loc=2)\n",
    "    # else:\n",
    "    #     ax.legend(loc=1)\n",
    "\n",
    "    ax.legend(loc=9)\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(ratios, ratios, rotation=90)\n",
    "    ax.set_xlim(0, 1)\n",
    "    if ylim:\n",
    "        ax.set_ylim(*ylim)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:53:46.544254Z",
     "end_time": "2023-05-03T14:53:46.546812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n"
     ]
    }
   ],
   "source": [
    "for fill in ('std', 'err'):\n",
    "    subdir = f'line_{fill}'\n",
    "    os.makedirs(os.path.join(plots_dir, subdir), exist_ok=True)\n",
    "\n",
    "    for ratio_type, ylim in [\n",
    "        ('ir', (-.9, .9)),\n",
    "        ('gr', (-.9, .9)),\n",
    "        ]:\n",
    "        for metric in fairness_results_cv['metric'].unique():\n",
    "            fig = plot_line(fairness_results_cv, metric, ratio_type, ylim=ylim, fill=fill)\n",
    "            fig.savefig(os.path.join(plots_dir, subdir, f'fairness_line_{ratio_type}_{metric}_rh.svg'))\n",
    "            plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:53:48.863996Z",
     "end_time": "2023-05-03T14:54:09.536151Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### plot absolute value of fairness metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def plot_line_abs(fairness: pd.DataFrame, metric: str, ratio_type: str, fill='std', ylim=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # ax.set_title(f'Value of *{metric}* for different {ratio_type.upper()}')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(ratio_type.upper())\n",
    "\n",
    "    metrics = fairness['metric'].unique()\n",
    "    clfs = fairness['clf'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "    mean, stdev, err = {}, {}, {}\n",
    "\n",
    "    for r in ratios:\n",
    "        for clf in clfs:\n",
    "            subset = fairness[\n",
    "                (fairness[ratio_type] == r) &\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric) &\n",
    "                fairness['value'].notna()\n",
    "                ]\n",
    "            mean[(r, clf)] = subset['value'].abs().mean(skipna=True)\n",
    "            stdev[(r, clf)] = subset['value'].abs().std(skipna=True)\n",
    "            err[(r, clf)] = scipy.stats.sem(subset['value'].abs(), nan_policy='omit')\n",
    "\n",
    "    # ax.axhline(0, color='black', linestyle='--', alpha=.3)\n",
    "\n",
    "    for i, clf in enumerate(clfs):\n",
    "        ax.plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[i], marker='o')\n",
    "        if fill == 'err':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "        elif fill == 'std':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "\n",
    "    # if (metric == 'Negative Predictive Parity Difference' and ratio_type == 'ir') or \\\n",
    "    #         (metric == 'Statistical Parity Difference' and ratio_type == 'gr') or \\\n",
    "    #         metric == 'Predictive Equality Difference':\n",
    "    #     ax.legend(loc=2)\n",
    "    # else:\n",
    "    #     ax.legend(loc=1)\n",
    "    ax.legend(loc=9)\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(ratios, ratios, rotation=90)\n",
    "    ax.set_xlim(0, 1)\n",
    "    if ylim:\n",
    "        ax.set_ylim(*ylim)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:09.579591Z",
     "end_time": "2023-05-03T14:54:09.591158Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "for fill in ('std', 'err'):\n",
    "    subdir = f'line_abs_{fill}'\n",
    "    os.makedirs(os.path.join(plots_dir, subdir), exist_ok=True)\n",
    "\n",
    "    for ratio_type in ['ir', 'gr']:\n",
    "        # ratio_type = 'ir'\n",
    "        for metric in fairness_results_cv['metric'].unique():\n",
    "            fig = plot_line_abs(fairness_results_cv, metric, ratio_type, ylim=(0, .6), fill=fill)\n",
    "            fig.savefig(os.path.join(plots_dir, subdir, f'fairness_line_{ratio_type}_{metric}_{fill}_abs_rh.svg'))\n",
    "            plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:09.579857Z",
     "end_time": "2023-05-03T14:54:28.907114Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### count NaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "metric                                 clf               \nAccuracy Equality Difference           DecisionTree          0.000667\n                                       GaussianNB            0.000667\n                                       KNeighbors            0.000667\n                                       LogisticRegression    0.000667\n                                       RandomForest          0.000667\nEqual Opportunity Difference           DecisionTree          0.010667\n                                       GaussianNB            0.010667\n                                       KNeighbors            0.010667\n                                       LogisticRegression    0.010667\n                                       RandomForest          0.010667\nNegative Predictive Parity Difference  DecisionTree          0.016667\n                                       GaussianNB            0.025333\n                                       KNeighbors            0.108667\n                                       LogisticRegression    0.080667\n                                       RandomForest          0.062667\nPositive Predictive Parity Difference  DecisionTree          0.026000\n                                       GaussianNB            0.057333\n                                       KNeighbors            0.090000\n                                       LogisticRegression    0.066000\n                                       RandomForest          0.076000\nPredictive Equality Difference         DecisionTree          0.010667\n                                       GaussianNB            0.010667\n                                       KNeighbors            0.010667\n                                       LogisticRegression    0.010667\n                                       RandomForest          0.010667\nStatistical Parity                     DecisionTree          0.000667\n                                       GaussianNB            0.000667\n                                       KNeighbors            0.000667\n                                       LogisticRegression    0.000667\n                                       RandomForest          0.000667\nName: value, dtype: float64"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count nan for each metric\n",
    "fairness_results_cv.groupby(['metric', 'clf'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:07:48.684952Z",
     "end_time": "2023-04-27T11:07:48.685071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "metric                        clf           gr  \nAccuracy Equality Difference  DecisionTree  0.01    0.00\n                                            0.02    0.00\n                                            0.05    0.00\n                                            0.10    0.00\n                                            0.20    0.00\n                                                    ... \nStatistical Parity            RandomForest  0.80    0.00\n                                            0.90    0.00\n                                            0.95    0.00\n                                            0.98    0.00\n                                            0.99    0.02\nName: value, Length: 450, dtype: float64"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fairness_results_cv[\n",
    "#     (fairness_results_cv['metric'] == 'Negative Predictive Parity Difference') |\n",
    "#     (fairness_results_cv['metric'] == 'Positive Predictive Parity Difference')\n",
    "# ].groupby(['metric', 'clf', 'gr'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "fairness_results_cv.groupby(['metric', 'clf', 'gr'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:20:51.462594Z",
     "end_time": "2023-04-27T11:20:51.462716Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "metric                        clf           ir  \nAccuracy Equality Difference  DecisionTree  0.01    0.0\n                                            0.02    0.0\n                                            0.05    0.0\n                                            0.10    0.0\n                                            0.20    0.0\n                                                   ... \nStatistical Parity            RandomForest  0.80    0.0\n                                            0.90    0.0\n                                            0.95    0.0\n                                            0.98    0.0\n                                            0.99    0.0\nName: value, Length: 450, dtype: float64"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fairness_results_cv[\n",
    "#     (fairness_results_cv['metric'] == 'Negative Predictive Parity Difference') |\n",
    "#     (fairness_results_cv['metric'] == 'Positive Predictive Parity Difference')\n",
    "#     ].groupby(['metric', 'clf', 'ir'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "fairness_results_cv.groupby(['metric', 'clf', 'ir'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:20:52.482109Z",
     "end_time": "2023-04-27T11:20:52.482191Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### plot nan count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def plot_nan(fairness, ratio_type, clfs=None, metrics=None, ylim=None):\n",
    "    if clfs is None:\n",
    "        clfs = fairness['clf'].unique()\n",
    "    if metrics is None:\n",
    "        metrics = fairness['metric'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(metrics) - 1) // 2 + 1,\n",
    "                           sharex=True, sharey=True,\n",
    "                           figsize=(16, 9))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax[i % 2, i // 2].set_title(metric)\n",
    "        ax[i % 2, i // 2].set_ylabel('NaN probability')\n",
    "        ax[i % 2, i // 2].set_xlabel(ratio_type.upper())\n",
    "        ax[i % 2, i // 2].yaxis.set_major_formatter(PercentFormatter(1))\n",
    "        ax[i % 2, i // 2].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "        for j, clf in enumerate(clfs):\n",
    "            subset = fairness[\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric)\n",
    "                ]\n",
    "            counts = subset.groupby(ratio_type)['value'].apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "            ax[i % 2, i // 2].plot(ratios, counts,\n",
    "                                   label=clf, color=colours[j], marker='o', alpha=.6)\n",
    "\n",
    "    if ylim:\n",
    "        ax[0, 0].set_ylim(*ylim)\n",
    "    else:\n",
    "        ax[0, 0].set_ylim(0, ax[0, 0].get_ylim()[1] * 1.1)\n",
    "    ax[0, 0].set_xlim(0, 1)\n",
    "    ax[0, 0].legend(loc=0)\n",
    "\n",
    "    return fig\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:35.196443Z",
     "end_time": "2023-05-03T14:54:35.203882Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "for ratio_type in ['ir', 'gr']:\n",
    "    fig = plot_nan(fairness_results_cv, ratio_type,\n",
    "                   metrics=[\n",
    "                       'Accuracy Equality Difference',\n",
    "                       'Statistical Parity Difference',\n",
    "                       'Equal Opportunity Difference',\n",
    "                       'Predictive Equality Difference',\n",
    "                       'Positive Predictive Parity Difference',\n",
    "                       'Negative Predictive Parity Difference',\n",
    "                   ])\n",
    "    fig.savefig(os.path.join(plots_dir, f'fairness_nan_{ratio_type}.svg'))\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:37.276486Z",
     "end_time": "2023-05-03T14:54:38.163777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# pickle the results\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join('out', 'fairness_results_cv.pkl'), 'wb') as f:\n",
    "    pickle.dump(fairness_results_cv, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T16:16:29.909151Z",
     "end_time": "2023-05-03T16:16:29.925831Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
