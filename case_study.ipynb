{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adult Dataset, aka Census income\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/adult"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, ShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "plt.style.use('default')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:08:47.292075Z",
     "end_time": "2023-04-27T21:08:47.293400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:08:47.452815Z",
     "end_time": "2023-04-27T21:08:47.452989Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25094/1575989903.py:17: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dataset = pd.read_csv('data/adult.data', sep=', ', na_values=['?', ' ?'],\n"
     ]
    },
    {
     "data": {
      "text/plain": "   age         workclass  education  education-num      marital-status  \\\n0   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n1   38           Private    HS-grad              9            Divorced   \n2   53           Private       11th              7  Married-civ-spouse   \n3   28           Private  Bachelors             13  Married-civ-spouse   \n4   37           Private    Masters             14  Married-civ-spouse   \n\n          occupation   relationship   race     sex  capital-gain  \\\n0    Exec-managerial        Husband  White    Male             0   \n1  Handlers-cleaners  Not-in-family  White    Male             0   \n2  Handlers-cleaners        Husband  Black    Male             0   \n3     Prof-specialty           Wife  Black  Female             0   \n4    Exec-managerial           Wife  White  Female             0   \n\n   capital-loss  hours-per-week native-country income  \n0             0              13  United-States  <=50K  \n1             0              40  United-States  <=50K  \n2             0              40  United-States  <=50K  \n3             0              40           Cuba  <=50K  \n4             0              40  United-States  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37</td>\n      <td>Private</td>\n      <td>Masters</td>\n      <td>14</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',       # removed\n",
    "    'education',    # sorted later on\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "]\n",
    "dataset = pd.read_csv('data/adult.data', sep=', ', na_values=['?', ' ?'],\n",
    "                      header=0, names=features + ['income'])\n",
    "dataset.drop(columns=['fnlwgt'], inplace=True)\n",
    "features.remove('fnlwgt')\n",
    "\n",
    "plots_dir = os.path.join('out', 'plots', 'case_study', 'census_income')\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## decide on the possible subset size\n",
    "\n",
    "groups: sex\n",
    "class: income (1: >=50k)\n",
    "\n",
    "IR = GR = .5\n",
    "IR = .5, GR = .05\n",
    "IR = .05, GR = .5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32560, 14)\n",
      "10771\n",
      "21789\n",
      "24719\n",
      "7841\n",
      "F 1/2: 12925.199999999999\n",
      "F 1/20: 129251.99999999999\n",
      "M 1/2: 26146.8\n",
      "M 19/20: 13761.473684210527\n",
      "0 1/2: 29662.8\n",
      "0 19/20: 15612.0\n",
      "1 1/2: 9409.199999999999\n",
      "1 1/20: 94091.99999999999\n",
      " -> 9409.199999999999\n"
     ]
    }
   ],
   "source": [
    "# decide on the split size\n",
    "\n",
    "print(\n",
    "    dataset.shape,\n",
    "    dataset[dataset['sex'] == 'Female'].shape[0],\n",
    "    dataset[dataset['sex'] != 'Female'].shape[0],\n",
    "    dataset[dataset['income'] != '>50K'].shape[0],\n",
    "    dataset[dataset['income'] == '>50K'].shape[0],\n",
    "    # dataset[(dataset['income'] == '>50K') & (dataset['sex'] == 'Female')].shape,\n",
    "    sep='\\n'\n",
    ")\n",
    "\n",
    "max_n = dataset.shape[0]\n",
    "max_random = .6\n",
    "\n",
    "for split, ratio, desc in [\n",
    "    (dataset['sex'] == 'Female', .5, 'F 1/2'),\n",
    "    (dataset['sex'] == 'Female', .05, 'F 1/20'),\n",
    "\n",
    "    (dataset['sex'] == 'Male', .5, 'M 1/2'),\n",
    "    (dataset['sex'] == 'Male', .95, 'M 19/20'),\n",
    "\n",
    "    (dataset['income'] == '<=50K', .5, '0 1/2'),\n",
    "    (dataset['income'] == '<=50K', .95, '0 19/20'),\n",
    "\n",
    "    (dataset['income'] == '>50K', .5, '1 1/2'),\n",
    "    (dataset['income'] == '>50K', .05, '1 1/20'),\n",
    "]:\n",
    "    n = dataset[split].shape[0] * max_random / ratio\n",
    "    print(f'{desc}: {n}')\n",
    "    if n < max_n:\n",
    "        max_n = n\n",
    "\n",
    "print(f' -> {max_n}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T11:49:32.755790Z",
     "end_time": "2023-04-26T11:49:32.783053Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 1/2\t0.4177885061739857\n",
      "F 1/20\t0.04177885061739857\n",
      "M 1/2\t0.20652622883106153\n",
      "M 19/20\t0.3923998347790169\n",
      "0 1/2\t0.18204619927990615\n",
      "0 19/20\t0.3458877786318217\n",
      "1 1/2\t0.5739063894911364\n",
      "1 1/20\t0.057390638949113636\n"
     ]
    }
   ],
   "source": [
    "max_n = 9000\n",
    "\n",
    "for split, ratio, desc in [\n",
    "    (dataset['sex'] == 'Female', .5, 'F 1/2'),\n",
    "    (dataset['sex'] == 'Female', .05, 'F 1/20'),\n",
    "\n",
    "    (dataset['sex'] == 'Male', .5, 'M 1/2'),\n",
    "    (dataset['sex'] == 'Male', .95, 'M 19/20'),\n",
    "\n",
    "    (dataset['income'] == '<=50K', .5, '0 1/2'),\n",
    "    (dataset['income'] == '<=50K', .95, '0 19/20'),\n",
    "\n",
    "    (dataset['income'] == '>50K', .5, '1 1/2'),\n",
    "    (dataset['income'] == '>50K', .05, '1 1/20'),\n",
    "]:\n",
    "    print(desc, max_n * ratio / dataset[split].shape[0], sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T11:31:59.584044Z",
     "end_time": "2023-04-19T11:31:59.600931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 0: 9592\n",
      "F 1: 1179\n",
      "M 0: 15127\n",
      "M 1: 6662\n"
     ]
    }
   ],
   "source": [
    "# check set intersections\n",
    "conditions_g = [\n",
    "    (dataset['sex'] == 'Female', 'F'),\n",
    "    (dataset['sex'] == 'Male', 'M'),\n",
    "]\n",
    "\n",
    "conditions_i = [\n",
    "    (dataset['income'] == '<=50K', '0'),\n",
    "    (dataset['income'] == '>50K', '1'),\n",
    "]\n",
    "\n",
    "for c_g, g in conditions_g:\n",
    "    for c_i, i in conditions_i:\n",
    "        print(f'{g} {i}: {dataset[c_g & c_i].shape[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T12:14:53.782552Z",
     "end_time": "2023-04-19T12:14:53.831864Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## different approaches for creating subsets\n",
    "\n",
    "### split approach 1: \"ladies first\"\n",
    "1. sample the needed number of women\n",
    "1. calculate the number of rows of each class that we got in this way, and replace if there's too many of one class\n",
    "1. calculate how many men of each class we need to get the desired ratio\n",
    "1. sample the men (separately for each class) and join all the selected samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# [majority, minority]\n",
    "sex = ['Male', 'Female']\n",
    "income = ['<=50K', '>50K']\n",
    "\n",
    "def split_03(dset, n, gr, ir):\n",
    "    cls_n = [int(n * (1 - ir)), int(n * ir)]\n",
    "    sex_n = [int(n * (1 - gr)), int(n * gr)]\n",
    "\n",
    "    # decide ratio of poor/rich women, based on the ratio from original data\n",
    "    og0 = dset[(dset['sex'] == sex[1]) & (dset['income'] == income[0])].shape[0] / dset[dset['sex'] == sex[1]].shape[0]\n",
    "    # og1 = dset[(dset['sex'] == sex[1]) & (dset['income'] == income[1])].shape[0] / dset.shape[0]\n",
    "    print(og0)\n",
    "\n",
    "    f0 = round(sex_n[1] * og0)\n",
    "    f1 = sex_n[1] - f0\n",
    "    print('f: ', f0, f1)\n",
    "\n",
    "    # sample women\n",
    "    df = pd.concat([\n",
    "        dset[(dset['sex'] == sex[1]) & (dset['income'] == income[0])].sample(n=f0, random_state=2137),\n",
    "        dset[(dset['sex'] == sex[1]) & (dset['income'] == income[1])].sample(n=f1, random_state=2137),\n",
    "    ])\n",
    "    print('f: ', f0, f1)\n",
    "    assert f0 + f1 == sex_n[1]\n",
    "\n",
    "    # sample men\n",
    "    m0 = cls_n[0] - f0\n",
    "    m1 = cls_n[1] - f1\n",
    "    print(\"m: \", m0, m1)\n",
    "    assert m0 + m1 == sex_n[0]\n",
    "\n",
    "    df_m0 = dset[\n",
    "        (dset['sex'] == sex[0]) & (dset['income'] == income[0])\n",
    "        ].sample(n=m0, random_state=2137)\n",
    "    df_m1 = dset[\n",
    "        (dset['sex'] == sex[0]) & (dset['income'] == income[1])\n",
    "        ].sample(n=m1, random_state=2137)\n",
    "\n",
    "    # print(df_m0.shape, df_m1.shape)\n",
    "    df = pd.concat([df, df_m0, df_m1])\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T15:04:51.081968Z",
     "end_time": "2023-04-26T15:04:51.087560Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### split approach 2: set ratios in advance\n",
    "\n",
    "1. decide on number of f0, f1, m0, m1\n",
    "2. sample accordingly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "n = dataset.shape[0]\n",
    "gr = ir = .5\n",
    "\n",
    "# [majority, minority]\n",
    "sex = ['Male', 'Female']\n",
    "income = ['<=50K', '>50K']\n",
    "\n",
    "\n",
    "def split_02(df, n, gr, ir, group_swap=False, cls_swap=False):\n",
    "    \"\"\"\n",
    "    :param df: original data\n",
    "    :param n: final size of the sample\n",
    "    :param cls_swap: if you want to swap the groups (i.e. get `gr` men and not women)\n",
    "    :param group_swap: if want to swap the decision classes (i.e. get `ir`of the poor and not the rich)\n",
    "    :return: the sample\n",
    "    \"\"\"\n",
    "    data_len = df.shape[0]\n",
    "    # set ratios of sex and income\n",
    "    f0 = round(n * gr * (1 - ir))\n",
    "    f1 = round(n * gr * ir)\n",
    "    m0 = round(n * (1 - gr) * (1 - ir))\n",
    "    m1 = round(n * (1 - gr) * ir)\n",
    "\n",
    "    if group_swap:\n",
    "        f0, f1, m0, m1 = m0, m1, f0, f1\n",
    "    if cls_swap:\n",
    "        f0, f1, m0, m1 = f1, f0, m1, m0\n",
    "    print(f0, f1, m0, m1)\n",
    "\n",
    "    sample = pd.concat([\n",
    "        df[(df['sex'] == sex[1]) & (df['income'] == income[0])].sample(n=int(f0), random_state=2137),\n",
    "        df[(df['sex'] == sex[1]) & (df['income'] == income[1])].sample(n=int(f1), random_state=2137),\n",
    "        df[(df['sex'] == sex[0]) & (df['income'] == income[0])].sample(n=int(m0), random_state=2137),\n",
    "        df[(df['sex'] == sex[0]) & (df['income'] == income[1])].sample(n=int(m1), random_state=2137),\n",
    "    ]).reset_index(drop=True)\n",
    "    return sample\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:08:58.488960Z",
     "end_time": "2023-04-27T21:08:58.489175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def split_04(dset, n, gr, ir):\n",
    "    cls_n = [int(n * (1 - ir)), int(n * ir)]\n",
    "    sex_n = [int(n * (1 - gr)), int(n * gr)]\n",
    "    print('cls: ', cls_n)\n",
    "    print('sex: ', sex_n)\n",
    "\n",
    "    f1_max = min(cls_n[0], sex_n[1], dset[(dset['sex'] == sex[1]) & (dset['income'] == income[1])].shape[0])\n",
    "    f1 = round(min(\n",
    "        np.random.normal(f1_max / 2, f1_max / 5),\n",
    "        f1_max,\n",
    "        cls_n[1],\n",
    "        sex_n[1],\n",
    "    ) * .9)\n",
    "    f0 = sex_n[1] - f1\n",
    "    m0 = cls_n[0] - f0\n",
    "    m1 = sex_n[0] - m0\n",
    "\n",
    "    print(f0, f1, m0, m1)\n",
    "\n",
    "    sample = pd.concat([\n",
    "        dset[(dset['sex'] == sex[1]) & (dset['income'] == income[0])].sample(n=int(f0), random_state=2137),\n",
    "        dset[(dset['sex'] == sex[1]) & (dset['income'] == income[1])].sample(n=int(f1), random_state=2137),\n",
    "        dset[(dset['sex'] == sex[0]) & (dset['income'] == income[0])].sample(n=int(m0), random_state=2137),\n",
    "        dset[(dset['sex'] == sex[0]) & (dset['income'] == income[1])].sample(n=int(m1), random_state=2137),\n",
    "    ]).reset_index(drop=True)\n",
    "    return sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T15:20:26.058347Z",
     "end_time": "2023-04-26T15:20:26.060947Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## preprocessing and helpers for classification/evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "categorical_fs = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "]\n",
    "\n",
    "education_order = [\n",
    "    'Preschool',\n",
    "    '1st-4th',\n",
    "    '5th-6th',\n",
    "    '7th-8th',\n",
    "    '9th',\n",
    "    '10th',\n",
    "    '11th',\n",
    "    '12th',\n",
    "    'HS-grad',\n",
    "    'Some-college',\n",
    "    'Assoc-acdm',\n",
    "    'Assoc-voc',\n",
    "    'Bachelors',\n",
    "    'Masters',\n",
    "    'Prof-school',\n",
    "    'Doctorate',\n",
    "]\n",
    "\n",
    "# get the columns in the correct order\n",
    "cols = np.concatenate([dataset.columns.copy(deep=True).drop(categorical_fs + ['income']), categorical_fs])\n",
    "cols_d = {c: i for i, c in enumerate(cols)}\n",
    "\n",
    "classifiers = [\n",
    "    [RandomForestClassifier, {'random_state': 2137}],\n",
    "    [DecisionTreeClassifier, {'random_state': 2137}],\n",
    "    [GaussianNB, {}],\n",
    "    [LogisticRegression, {}],\n",
    "    [KNeighborsClassifier, {}],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:09:00.099958Z",
     "end_time": "2023-04-27T21:09:00.100133Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    X_all = dataset[features]\n",
    "    y_all = LabelEncoder().fit_transform(dataset['income'])\n",
    "\n",
    "    # encode categorical features\n",
    "    data_encoder = OrdinalEncoder().fit(X_all[categorical_fs])\n",
    "    X_categorical = data_encoder.transform(X_all[categorical_fs])\n",
    "\n",
    "    edu_encoder = OrdinalEncoder(categories=[education_order]).fit(X_all[['education']])\n",
    "    X_categorical[:, categorical_fs.index('education')] = edu_encoder.transform(X_all[['education']])[0]\n",
    "\n",
    "    # finally, the features\n",
    "    X_all = np.concatenate([X_all.drop(categorical_fs, axis=1), X_categorical], axis=1)\n",
    "    # X_all[:5]\n",
    "\n",
    "    return X_all, y_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:09:00.365416Z",
     "end_time": "2023-04-27T21:09:00.365555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def calculate_fairness(clf, X, y, protected, group=1, cls=1):\n",
    "    \"\"\"\n",
    "    :param protected: id/name of the protected attribute column\n",
    "    :param group: id of the protected group\n",
    "    :param cls: id of the positive class\n",
    "    :return: dictionary of fairness metrics for the given classifier's results\n",
    "    \"\"\"\n",
    "    y_pred = clf.predict(X)\n",
    "    # columns: protected_value, y_true, y_pred\n",
    "    labelled = np.concatenate([\n",
    "        X[:, protected].reshape(-1, 1),\n",
    "        y.reshape(-1, 1),\n",
    "        y_pred.reshape(-1, 1)\n",
    "    ], axis=1)\n",
    "\n",
    "    # calculate confusion matrices\n",
    "    cms = [None, None]\n",
    "\n",
    "    # y true/pred for the protected group\n",
    "    ys = labelled[labelled[:, 0] == group]\n",
    "    cms[0] = confusion_matrix(ys[:, 1], ys[:, 2], labels=[0, 1])\n",
    "    # ... and for the other (unprotected) group\n",
    "    ys = labelled[labelled[:, 0] != group]\n",
    "    cms[1] = confusion_matrix(ys[:, 1], ys[:, 2], labels=[0, 1])\n",
    "\n",
    "    # print(*cms, sep='\\n')\n",
    "\n",
    "    # mj = majority - unprotected\n",
    "    # mr = minority - protected\n",
    "    mr, mj = group, 1 - group\n",
    "    pos, neg = cls, 1 - cls\n",
    "\n",
    "    # labels for the confusion matrix items\n",
    "    tn = (neg, neg)\n",
    "    fp = (neg, pos)\n",
    "    fn = (pos, neg)\n",
    "    tp = (pos, pos)\n",
    "\n",
    "    # calculate fairness metrics\n",
    "    fairness = dict()\n",
    "\n",
    "    # Accuracy Equality Difference\n",
    "    fairness['Accuracy Equality Difference'] = \\\n",
    "        (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
    "        (cms[mr].item(tp) + cms[mr].item(tn)) / cms[mr].sum()\n",
    "\n",
    "    # Equal Opportunity Difference: j_tpr - i_tpr\n",
    "    try:\n",
    "        fairness['Equal Opportunity Difference'] = \\\n",
    "            cms[mj].item(tp) / (cms[mj].item(tp) + cms[mj].item(fn)) - \\\n",
    "            cms[mr].item(tp) / (cms[mr].item(tp) + cms[mr].item(fn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Equal Opportunity Difference'] = np.nan\n",
    "\n",
    "    # Predictive Equality Difference: j_fpr - i_fpr\n",
    "    try:\n",
    "        fairness['Predictive Equality Difference'] = \\\n",
    "            cms[mj].item(fp) / (cms[mj].item(fp) + cms[mj].item(tn)) - \\\n",
    "            cms[mr].item(fp) / (cms[mr].item(fp) + cms[mr].item(tn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Predictive Equality Difference'] = np.nan\n",
    "\n",
    "    # Positive Predictive Parity Difference: j_ppv - i_ppv\n",
    "    try:\n",
    "        fairness['Positive Predictive Parity Difference'] = \\\n",
    "            cms[mj].item(tp) / (cms[mj].item(tp) + cms[mj].item(fp)) - \\\n",
    "            cms[mr].item(tp) / (cms[mr].item(tp) + cms[mr].item(fp))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Positive Predictive Parity Difference'] = np.nan\n",
    "\n",
    "    # Negative Predictive Parity Difference: j_npv - i_npv\n",
    "    try:\n",
    "        fairness['Negative Predictive Parity Difference'] = \\\n",
    "            cms[mj].item(tn) / (cms[mj].item(tn) + cms[mj].item(fn)) - \\\n",
    "            cms[mr].item(tn) / (cms[mr].item(tn) + cms[mr].item(fn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Negative Predictive Parity Difference'] = np.nan\n",
    "\n",
    "    fairness['Statistical Parity Difference'] = \\\n",
    "        (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
    "        (cms[mr].item(tp) + cms[mr].item(fp)) / cms[mr].sum()\n",
    "\n",
    "    return fairness"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:09:00.931474Z",
     "end_time": "2023-04-27T21:09:00.931679Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# medium-contrast scheme from https://personal.sron.nl/~pault/\n",
    "colours = ['#6699CC', '#004488', '#EECC66', '#994455', '#997700', '#EE99AA']\n",
    "\n",
    "# group by metric\n",
    "def plot_fairness_gb_metric(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = ['\\n'.join([' '.join(f.split(\" \")[:2]), ' '.join(f.split(\" \")[2:])])\n",
    "               for f in fairness[list(fairness.keys())[0]].keys()]\n",
    "    xticks = np.arange(len(metrics))\n",
    "    width = 1. / (len(fairness.keys()) + 2)\n",
    "\n",
    "    for i, (clf, f) in enumerate(fairness.items()):\n",
    "        ax.bar(xticks + i * width, f.values(), width, label=clf.replace('Classifier', ''), color=colours[i])\n",
    "\n",
    "    ax.set_xticks(xticks + width * len(fairness.keys()) / 2, metrics, rotation=45)\n",
    "    ax.legend(ncols=1)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_fairness_gb_clf(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = fairness[list(fairness.keys())[0]].keys()\n",
    "    classifiers = [c.replace('Classifier', '') for c in fairness.keys()]\n",
    "    xticks = np.arange(len(classifiers))\n",
    "    width = 1. / (len(metrics) + 2)\n",
    "    shift = np.arange(len(metrics)) * width\n",
    "\n",
    "    for i, (clf, f) in enumerate(fairness.items()):\n",
    "        ax.bar(i + shift, f.values(), width, color=colours[:len(metrics)])\n",
    "    # ax.bar(xticks + shift, fairness, width)\n",
    "    ax.set_xticks(xticks + width * len(metrics) / 2, classifiers)\n",
    "    ax.legend(handles=[mpatches.Patch(color=c, label=m) for c, m in zip(colours, metrics)], ncol=1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:09:03.457510Z",
     "end_time": "2023-04-27T21:09:03.457650Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## classification\n",
    "\n",
    "### simple one, no CV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split = split_02\n",
    "SAMPLE_SIZE = 4000\n",
    "\n",
    "rs = [.01, .02, .05] + list(np.arange(.1, 1., .1)) + [.95, .98, .99]\n",
    "ratios = [[.5, ir] for ir in rs] + [[gr, .5] for gr in rs]\n",
    "\n",
    "for gr, ir in ratios:\n",
    "    print(f'GR: {gr}, IR: {ir}')\n",
    "\n",
    "    # # because we don't have enough rich women in the dataset\n",
    "    # if gr > .5:\n",
    "    #     swap_gr = True\n",
    "    # if ir > .5:\n",
    "    #     swap_ir = True\n",
    "\n",
    "    df = split(dataset, SAMPLE_SIZE, gr, ir)\n",
    "    X_all, y_all = preprocess(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=2137)\n",
    "    fairness_results = dict()\n",
    "\n",
    "    for clf, kwargs in classifiers:\n",
    "        print(clf.__name__,)\n",
    "        pipe = make_pipeline(\n",
    "            KNNImputer(),\n",
    "            StandardScaler(),\n",
    "            clf(**kwargs)\n",
    "        ).fit(X_train, y_train)\n",
    "\n",
    "        # print(pipe.score(X_test, y_test))\n",
    "        f = calculate_fairness(pipe, X_test, y_test, cols_d['sex'])\n",
    "        # print(f)\n",
    "        fairness_results[clf.__name__] = f\n",
    "\n",
    "    fig = plot_fairness_gb_metric(fairness_results, gr, ir)\n",
    "    fig.savefig(os.path.join(plots_dir, f'fairness_metric_gr{gr}_ir{ir}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    fig = plot_fairness_gb_clf(fairness_results, gr, ir)\n",
    "    fig.savefig(os.path.join(plots_dir, f'fairness_clf_gr{gr}_ir{ir}.png'))\n",
    "    plt.close()\n",
    "    print(\"=== ---- ===\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T02:58:27.065650Z",
     "end_time": "2023-04-25T02:58:32.114445Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# TODO add error bars and write mean values\n",
    "\n",
    "# group by metric\n",
    "def plot_fairness_gb_metric_cv(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = set([m for _, _, _, m in fairness.keys()])\n",
    "    clfs = set([c.replace('Classifier', '') for _, _, c, _ in fairness.keys()])\n",
    "\n",
    "    xticks = np.arange(len(metrics))\n",
    "    width = 1. / (len(clfs) + 2)\n",
    "\n",
    "    for i, clf in enumerate(clfs):\n",
    "        ax.bar(xticks + i * width, [np.nanmean(fairness[(gr, ir, clf, m)]) for m in metrics],\n",
    "               width, label=clf, color=colours[i])\n",
    "\n",
    "    ax.set_xticks(xticks + width * len(clfs) / 2, metrics, rotation=45)\n",
    "    ax.legend(ncols=1)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_fairness_gb_clf_cv(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = set([m for _, _, _, m in fairness.keys()])\n",
    "    clfs = set([c.replace('Classifier', '') for _, _, c, _ in fairness.keys()])\n",
    "\n",
    "    xticks = np.arange(len(clfs))\n",
    "    width = 1. / (len(metrics) + 2)\n",
    "    # shift = np.arange(len(metrics)) * width\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax.bar(xticks + i * width, [np.nanmean(fairness[(gr, ir, c, metric)]) for c in clfs],\n",
    "               width, label=metric, color=colours[i])\n",
    "    ax.set_xticks(xticks + width * len(metrics) / 2, clfs)\n",
    "    ax.legend(ncols=1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T22:35:47.159517Z",
     "end_time": "2023-04-26T22:35:47.204044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GR: 0.1, IR: 0.1\n",
      "cls:  [3960, 440]\n",
      "sex:  [3960, 440]\n",
      "364 76 3596 364\n",
      "GR: 0.1, IR: 0.25\n",
      "cls:  [3300, 1100]\n",
      "sex:  [3960, 440]\n",
      "126 314 3174 786\n",
      "GR: 0.1, IR: 0.5\n",
      "cls:  [2200, 2200]\n",
      "sex:  [3960, 440]\n",
      "324 116 1876 2084\n",
      "GR: 0.25, IR: 0.1\n",
      "cls:  [3960, 440]\n",
      "sex:  [3300, 1100]\n",
      "704 396 3256 44\n",
      "GR: 0.25, IR: 0.25\n",
      "cls:  [3300, 1100]\n",
      "sex:  [3300, 1100]\n",
      "734 366 2566 734\n",
      "GR: 0.25, IR: 0.5\n",
      "cls:  [2200, 2200]\n",
      "sex:  [3300, 1100]\n",
      "709 391 1491 1809\n",
      "GR: 0.5, IR: 0.1\n",
      "cls:  [3960, 440]\n",
      "sex:  [2200, 2200]\n",
      "2037 163 1923 277\n",
      "GR: 0.5, IR: 0.25\n",
      "cls:  [3300, 1100]\n",
      "sex:  [2200, 2200]\n",
      "1595 605 1705 495\n",
      "GR: 0.5, IR: 0.5\n",
      "cls:  [2200, 2200]\n",
      "sex:  [2200, 2200]\n",
      "1518 682 682 1518\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True, random_state=2137)\n",
    "SAMPLE_SIZE = 4400\n",
    "split = split_04\n",
    "ratios = [\n",
    "    [gr, ir] for gr in [.1, .25, .5] for ir in [.1, .25, .5]\n",
    "]\n",
    "\n",
    "fairness_results_cv = {}\n",
    "\n",
    "for gr, ir in ratios:\n",
    "    print(f'GR: {gr}, IR: {ir}')\n",
    "    df = split(dataset, SAMPLE_SIZE, gr, ir)\n",
    "    X_all, y_all = preprocess(df)\n",
    "\n",
    "    for i, (traini, testi) in enumerate(cv.split(X_all)):\n",
    "        X_train, X_test = X_all[traini], X_all[testi]\n",
    "        y_train, y_test = y_all[traini], y_all[testi]\n",
    "\n",
    "        for clf, kwargs in classifiers:\n",
    "            pipe = make_pipeline(\n",
    "                KNNImputer(),\n",
    "                StandardScaler(),\n",
    "                clf(**kwargs)\n",
    "            ).fit(X_train, y_train)\n",
    "            f = calculate_fairness(pipe, X_test, y_test, cols_d['sex'])\n",
    "\n",
    "            for metric, value in f.items():\n",
    "                if (gr, ir, clf.__name__, metric) not in fairness_results_cv:\n",
    "                    fairness_results_cv[(gr, ir, clf.__name__.replace('Classifier', ''), metric)] = [value]\n",
    "                else:\n",
    "                    fairness_results_cv[(gr, ir, clf.__name__.replace('Classifier', ''), metric)].append(value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T11:50:10.911002Z",
     "end_time": "2023-04-26T11:51:30.007700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GR: 0.1, IR: 0.1\n",
      "=== ---- ===\n",
      "\n",
      "GR: 0.1, IR: 0.25\n",
      "=== ---- ===\n",
      "\n",
      "GR: 0.1, IR: 0.5\n",
      "=== ---- ===\n",
      "\n",
      "GR: 0.25, IR: 0.1\n",
      "=== ---- ===\n",
      "\n",
      "GR: 0.25, IR: 0.25\n",
      "=== ---- ===\n",
      "\n",
      "GR: 0.25, IR: 0.5\n",
      "=== ---- ===\n",
      "\n",
      "GR: 0.5, IR: 0.1\n",
      "=== ---- ===\n",
      "\n",
      "GR: 0.5, IR: 0.25\n",
      "=== ---- ===\n",
      "\n",
      "GR: 0.5, IR: 0.5\n",
      "=== ---- ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for gr, ir in ratios:\n",
    "    print(f'GR: {gr}, IR: {ir}')\n",
    "    fig = plot_fairness_gb_metric_cv(fairness_results_cv, gr, ir)\n",
    "    fig.savefig(os.path.join(plots_dir, f'fairness_gr{gr}_ir{ir}_metric_cv.png'))\n",
    "    plt.close()\n",
    "\n",
    "    fig = plot_fairness_gb_clf_cv(fairness_results_cv, gr, ir)\n",
    "    fig.savefig(os.path.join(plots_dir, f'fairness_gr{gr}_ir{ir}_clf_cv.png'))\n",
    "    plt.close()\n",
    "    print(\"=== ---- ===\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T03:50:27.691474Z",
     "end_time": "2023-04-25T03:50:27.691614Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Line graph: `fairness(ratio)`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "# cv = RepeatedKFold(n_splits=2, n_repeats=15, random_state=2137)    # 30 splits\n",
    "holdout = ShuffleSplit(n_splits=50, test_size=.33, random_state=2137)\n",
    "SAMPLE_SIZE = 1100\n",
    "split = split_02\n",
    "\n",
    "rs = [.01, .02, .05] + [round(x, 2) for x in np.arange(.1, 1., .1)] + [.95, .98, .99]\n",
    "# rs = [.02, .05] + [round(x, 2) for x in np.arange(.1, 1., .1)] + [.95, .98]\n",
    "ratios = [[.5, ir] for ir in rs] + [[gr, .5] for gr in rs]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T10:30:22.829612Z",
     "end_time": "2023-04-27T10:30:22.829738Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GR: 0.5, IR: 0.01\n",
      "544 6 544 6\n",
      "GR: 0.5, IR: 0.02\n",
      "539 11 539 11\n",
      "GR: 0.5, IR: 0.05\n",
      "522 28 522 28\n",
      "GR: 0.5, IR: 0.1\n",
      "495 55 495 55\n",
      "GR: 0.5, IR: 0.2\n",
      "440 110 440 110\n",
      "GR: 0.5, IR: 0.3\n",
      "385 165 385 165\n",
      "GR: 0.5, IR: 0.4\n",
      "330 220 330 220\n",
      "GR: 0.5, IR: 0.5\n",
      "275 275 275 275\n",
      "GR: 0.5, IR: 0.6\n",
      "220 330 220 330\n",
      "GR: 0.5, IR: 0.7\n",
      "165 385 165 385\n",
      "GR: 0.5, IR: 0.8\n",
      "110 440 110 440\n",
      "GR: 0.5, IR: 0.9\n",
      "55 495 55 495\n",
      "GR: 0.5, IR: 0.95\n",
      "28 522 28 522\n",
      "GR: 0.5, IR: 0.98\n",
      "11 539 11 539\n",
      "GR: 0.5, IR: 0.99\n",
      "6 544 6 544\n",
      "GR: 0.01, IR: 0.5\n",
      "6 6 544 544\n",
      "GR: 0.02, IR: 0.5\n",
      "11 11 539 539\n",
      "GR: 0.05, IR: 0.5\n",
      "28 28 522 522\n",
      "GR: 0.1, IR: 0.5\n",
      "55 55 495 495\n",
      "GR: 0.2, IR: 0.5\n",
      "110 110 440 440\n",
      "GR: 0.3, IR: 0.5\n",
      "165 165 385 385\n",
      "GR: 0.4, IR: 0.5\n",
      "220 220 330 330\n",
      "GR: 0.5, IR: 0.5\n",
      "275 275 275 275\n",
      "GR: 0.6, IR: 0.5\n",
      "330 330 220 220\n",
      "GR: 0.7, IR: 0.5\n",
      "385 385 165 165\n",
      "GR: 0.8, IR: 0.5\n",
      "440 440 110 110\n",
      "GR: 0.9, IR: 0.5\n",
      "495 495 55 55\n",
      "GR: 0.95, IR: 0.5\n",
      "522 522 28 28\n",
      "GR: 0.98, IR: 0.5\n",
      "539 539 11 11\n",
      "GR: 0.99, IR: 0.5\n",
      "544 544 6 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7779/3134640404.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_7779/3134640404.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_7779/3134640404.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_7779/3134640404.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_7779/3134640404.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_7779/3134640404.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_7779/3134640404.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_7779/3134640404.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_7779/3134640404.py:44: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_7779/3134640404.py:80: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n"
     ]
    }
   ],
   "source": [
    "# calculations\n",
    "# fairness_results_cv = {}\n",
    "results = []\n",
    "\n",
    "for gr, ir in ratios:\n",
    "# for gr, ir in [[.5, .9], [.5, .01]]:\n",
    "    print(f'GR: {gr}, IR: {ir}')\n",
    "\n",
    "    # because we don't have enough rich women in the dataset\n",
    "    # swap_gr = True if gr > .5 else False\n",
    "    # swap_ir = True if ir > .5 else False\n",
    "    swap_gr, swap_ir = False, False\n",
    "\n",
    "    df = split(dataset, SAMPLE_SIZE, gr, ir, group_swap=swap_gr, cls_swap=swap_ir)\n",
    "    X_all, y_all = preprocess(df)\n",
    "\n",
    "    for i, (traini, testi) in enumerate(holdout.split(X_all)):\n",
    "        X_train, X_test = X_all[traini], X_all[testi]\n",
    "        y_train, y_test = y_all[traini], y_all[testi]\n",
    "\n",
    "        for clf, kwargs in classifiers:\n",
    "            pipe = make_pipeline(\n",
    "                KNNImputer(),\n",
    "                StandardScaler(),\n",
    "                clf(**kwargs)\n",
    "            ).fit(X_train, y_train)\n",
    "            f = calculate_fairness(pipe, X_test, y_test, cols_d['sex'], group=1-int(swap_gr), cls=1-int(swap_ir))\n",
    "\n",
    "            for metric, value in f.items():\n",
    "                results.append([gr, ir, clf.__name__.replace('Classifier', ''), metric, value])\n",
    "\n",
    "fairness_results_cv = pd.DataFrame(results, columns=['gr', 'ir', 'clf', 'metric', 'value'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T10:36:50.551935Z",
     "end_time": "2023-04-27T10:36:50.552521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "    gr   ir           clf                                 metric     value\n0  0.5  0.9  RandomForest           Accuracy Equality Difference -0.006685\n1  0.5  0.9  RandomForest           Equal Opportunity Difference -0.004770\n2  0.5  0.9  RandomForest         Predictive Equality Difference -0.079710\n3  0.5  0.9  RandomForest  Positive Predictive Parity Difference -0.004504\n4  0.5  0.9  RandomForest  Negative Predictive Parity Difference  0.056410",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gr</th>\n      <th>ir</th>\n      <th>clf</th>\n      <th>metric</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>0.9</td>\n      <td>RandomForest</td>\n      <td>Accuracy Equality Difference</td>\n      <td>-0.006685</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.9</td>\n      <td>RandomForest</td>\n      <td>Equal Opportunity Difference</td>\n      <td>-0.004770</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>0.9</td>\n      <td>RandomForest</td>\n      <td>Predictive Equality Difference</td>\n      <td>-0.079710</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>0.9</td>\n      <td>RandomForest</td>\n      <td>Positive Predictive Parity Difference</td>\n      <td>-0.004504</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>0.9</td>\n      <td>RandomForest</td>\n      <td>Negative Predictive Parity Difference</td>\n      <td>0.056410</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_results_cv.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T15:34:29.792751Z",
     "end_time": "2023-04-26T15:34:29.792851Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def plot_line(fairness: pd.DataFrame, metric: str, ratio_type: str, fill='std', ylim=(-.5, .5)):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # ax.set_title(f'Value of *{metric}* for different {ratio_type.upper()}')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(ratio_type.upper())\n",
    "\n",
    "    metrics = fairness['metric'].unique()\n",
    "    clfs = fairness['clf'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "    mean, stdev, err = {}, {}, {}\n",
    "\n",
    "    for r in ratios:\n",
    "        for clf in clfs:\n",
    "            subset = fairness[\n",
    "                (fairness[ratio_type] == r) &\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric) &\n",
    "                fairness['value'].notna()\n",
    "            ]\n",
    "            mean[(r, clf)] = subset['value'].mean(skipna=True)\n",
    "            stdev[(r, clf)] = subset['value'].std(skipna=True)\n",
    "            err[(r, clf)] = scipy.stats.sem(subset['value'], nan_policy='omit')\n",
    "\n",
    "    ax.axhline(0, color='black', linestyle='--', alpha=.3)\n",
    "\n",
    "    for i, clf in enumerate(clfs):\n",
    "        ax.plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[i], marker='o')\n",
    "        if fill == 'err':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "        elif fill == 'std':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "\n",
    "    # if (metric == 'Negative Predictive Parity Difference' and ratio_type == 'ir') or \\\n",
    "    #     (metric == 'Statistical Parity Difference' and ratio_type == 'gr') or \\\n",
    "    #     metric == 'Predictive Equality Difference':\n",
    "    #     ax.legend(loc=2)\n",
    "    # else:\n",
    "    #     ax.legend(loc=1)\n",
    "\n",
    "    ax.legend(loc=9)\n",
    "\n",
    "    ax.set_xticks(ratios, ratios, rotation=90)\n",
    "    ax.set_xlim(0, 1)\n",
    "    if ylim:\n",
    "        ax.set_ylim(*ylim)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T10:54:28.318975Z",
     "end_time": "2023-04-27T10:54:28.319109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n"
     ]
    }
   ],
   "source": [
    "for fill in ('std', 'err'):\n",
    "    subdir = f'line_{fill}'\n",
    "    os.makedirs(os.path.join(plots_dir, subdir), exist_ok=True)\n",
    "\n",
    "    for ratio_type, ylim in [\n",
    "        ('ir', (-.9, .9)),\n",
    "        ('gr', (-.9, .9)),\n",
    "        ]:\n",
    "        for metric in fairness_results_cv['metric'].unique():\n",
    "            fig = plot_line(fairness_results_cv, metric, ratio_type, ylim=ylim, fill=fill)\n",
    "            fig.savefig(os.path.join(plots_dir, subdir, f'fairness_line_{ratio_type}_{metric}_rh.png'))\n",
    "            plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T10:54:37.218283Z",
     "end_time": "2023-04-27T10:54:37.218541Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### plot absolute value of fairness metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def plot_line_abs(fairness: pd.DataFrame, metric: str, ratio_type: str, fill='std', ylim=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # ax.set_title(f'Value of *{metric}* for different {ratio_type.upper()}')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(ratio_type.upper())\n",
    "\n",
    "    metrics = fairness['metric'].unique()\n",
    "    clfs = fairness['clf'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "    mean, stdev, err = {}, {}, {}\n",
    "\n",
    "    for r in ratios:\n",
    "        for clf in clfs:\n",
    "            subset = fairness[\n",
    "                (fairness[ratio_type] == r) &\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric) &\n",
    "                fairness['value'].notna()\n",
    "                ]\n",
    "            mean[(r, clf)] = subset['value'].abs().mean(skipna=True)\n",
    "            stdev[(r, clf)] = subset['value'].abs().std(skipna=True)\n",
    "            err[(r, clf)] = scipy.stats.sem(subset['value'].abs(), nan_policy='omit')\n",
    "\n",
    "    # ax.axhline(0, color='black', linestyle='--', alpha=.3)\n",
    "\n",
    "    for i, clf in enumerate(clfs):\n",
    "        ax.plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[i], marker='o')\n",
    "        if fill == 'err':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "        elif fill == 'std':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "\n",
    "    # if (metric == 'Negative Predictive Parity Difference' and ratio_type == 'ir') or \\\n",
    "    #         (metric == 'Statistical Parity Difference' and ratio_type == 'gr') or \\\n",
    "    #         metric == 'Predictive Equality Difference':\n",
    "    #     ax.legend(loc=2)\n",
    "    # else:\n",
    "    #     ax.legend(loc=1)\n",
    "    ax.legend(loc=9)\n",
    "\n",
    "    ax.set_xticks(ratios, ratios, rotation=90)\n",
    "    ax.set_xlim(0, 1)\n",
    "    if ylim:\n",
    "        ax.set_ylim(*ylim)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T10:54:37.238742Z",
     "end_time": "2023-04-27T10:54:37.238859Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n"
     ]
    }
   ],
   "source": [
    "for fill in ('std', 'err'):\n",
    "    subdir = f'line_abs_{fill}'\n",
    "    os.makedirs(os.path.join(plots_dir, subdir), exist_ok=True)\n",
    "\n",
    "    for ratio_type in ['ir', 'gr']:\n",
    "        # ratio_type = 'ir'\n",
    "        for metric in fairness_results_cv['metric'].unique():\n",
    "            fig = plot_line_abs(fairness_results_cv, metric, ratio_type, ylim=(0, .6), fill=fill)\n",
    "            fig.savefig(os.path.join(plots_dir, subdir, f'fairness_line_{ratio_type}_{metric}_{fill}_abs_rh.png'))\n",
    "            plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T10:54:45.202988Z",
     "end_time": "2023-04-27T10:54:45.203168Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### count NaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "metric                                 clf               \nAccuracy Equality Difference           DecisionTree          0.000667\n                                       GaussianNB            0.000667\n                                       KNeighbors            0.000667\n                                       LogisticRegression    0.000667\n                                       RandomForest          0.000667\nEqual Opportunity Difference           DecisionTree          0.010667\n                                       GaussianNB            0.010667\n                                       KNeighbors            0.010667\n                                       LogisticRegression    0.010667\n                                       RandomForest          0.010667\nNegative Predictive Parity Difference  DecisionTree          0.016667\n                                       GaussianNB            0.025333\n                                       KNeighbors            0.108667\n                                       LogisticRegression    0.080667\n                                       RandomForest          0.062667\nPositive Predictive Parity Difference  DecisionTree          0.026000\n                                       GaussianNB            0.057333\n                                       KNeighbors            0.090000\n                                       LogisticRegression    0.066000\n                                       RandomForest          0.076000\nPredictive Equality Difference         DecisionTree          0.010667\n                                       GaussianNB            0.010667\n                                       KNeighbors            0.010667\n                                       LogisticRegression    0.010667\n                                       RandomForest          0.010667\nStatistical Parity                     DecisionTree          0.000667\n                                       GaussianNB            0.000667\n                                       KNeighbors            0.000667\n                                       LogisticRegression    0.000667\n                                       RandomForest          0.000667\nName: value, dtype: float64"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count nan for each metric\n",
    "fairness_results_cv.groupby(['metric', 'clf'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:07:48.684952Z",
     "end_time": "2023-04-27T11:07:48.685071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "metric                        clf           gr  \nAccuracy Equality Difference  DecisionTree  0.01    0.00\n                                            0.02    0.00\n                                            0.05    0.00\n                                            0.10    0.00\n                                            0.20    0.00\n                                                    ... \nStatistical Parity            RandomForest  0.80    0.00\n                                            0.90    0.00\n                                            0.95    0.00\n                                            0.98    0.00\n                                            0.99    0.02\nName: value, Length: 450, dtype: float64"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fairness_results_cv[\n",
    "#     (fairness_results_cv['metric'] == 'Negative Predictive Parity Difference') |\n",
    "#     (fairness_results_cv['metric'] == 'Positive Predictive Parity Difference')\n",
    "# ].groupby(['metric', 'clf', 'gr'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "fairness_results_cv.groupby(['metric', 'clf', 'gr'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:20:51.462594Z",
     "end_time": "2023-04-27T11:20:51.462716Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "metric                        clf           ir  \nAccuracy Equality Difference  DecisionTree  0.01    0.0\n                                            0.02    0.0\n                                            0.05    0.0\n                                            0.10    0.0\n                                            0.20    0.0\n                                                   ... \nStatistical Parity            RandomForest  0.80    0.0\n                                            0.90    0.0\n                                            0.95    0.0\n                                            0.98    0.0\n                                            0.99    0.0\nName: value, Length: 450, dtype: float64"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fairness_results_cv[\n",
    "#     (fairness_results_cv['metric'] == 'Negative Predictive Parity Difference') |\n",
    "#     (fairness_results_cv['metric'] == 'Positive Predictive Parity Difference')\n",
    "#     ].groupby(['metric', 'clf', 'ir'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "fairness_results_cv.groupby(['metric', 'clf', 'ir'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:20:52.482109Z",
     "end_time": "2023-04-27T11:20:52.482191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
