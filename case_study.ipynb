{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adult Dataset, aka Census income\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/adult"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "# colour scheme inspired by https://personal.sron.nl/~pault/\n",
    "colours = ['#EE7733', '#33BBEE', '#EE3377', '#888888', '#009988',]\n",
    "\n",
    "x_labels = {\n",
    "    'gr': 'Protected group ratio (GR)',\n",
    "    'ir': 'Imbalance ratio (IR)',\n",
    "}\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 13\n",
    "BIGGER_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T06:57:05.609767452Z",
     "start_time": "2023-05-07T06:57:04.293776326Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-07T06:57:18.086900469Z",
     "start_time": "2023-05-07T06:57:17.877235449Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9224/71344094.py:17: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dataset = pd.read_csv('data/adult.data', sep=', ', na_values=['?', ' ?'],\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',       # removed\n",
    "    'education',    # sorted later on\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "]\n",
    "dataset = pd.read_csv('data/adult.data', sep=', ', na_values=['?', ' ?'],\n",
    "                      header=0, names=features + ['income'])\n",
    "dataset.drop(columns=['fnlwgt'], inplace=True)\n",
    "features.remove('fnlwgt')\n",
    "\n",
    "plots_dir = os.path.join('out', 'plots', 'case_study', 'census_income')\n",
    "os.makedirs(plots_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### splitting the data into subsets\n",
    "\n",
    "To enable comparison for different GR and IR.\n",
    "\n",
    "The split is proportional to group/class sizes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "n = dataset.shape[0]\n",
    "gr = ir = .5\n",
    "\n",
    "# [majority, minority]\n",
    "sex = ['Male', 'Female']\n",
    "income = ['<=50K', '>50K']\n",
    "\n",
    "\n",
    "def split_data(df, n, gr, ir):\n",
    "    \"\"\"\n",
    "    :param df: original data\n",
    "    :param n: final size of the sample\n",
    "    :return: the sample\n",
    "    \"\"\"\n",
    "    # set ratios of sex and income\n",
    "    f0 = round(n * gr * (1 - ir))\n",
    "    f1 = round(n * gr * ir)\n",
    "    m0 = round(n * (1 - gr) * (1 - ir))\n",
    "    m1 = round(n * (1 - gr) * ir)\n",
    "\n",
    "    sample = pd.concat([\n",
    "        df[(df['sex'] == sex[1]) & (df['income'] == income[0])].sample(n=int(f0), random_state=2137),\n",
    "        df[(df['sex'] == sex[1]) & (df['income'] == income[1])].sample(n=int(f1), random_state=2137),\n",
    "        df[(df['sex'] == sex[0]) & (df['income'] == income[0])].sample(n=int(m0), random_state=2137),\n",
    "        df[(df['sex'] == sex[0]) & (df['income'] == income[1])].sample(n=int(m1), random_state=2137),\n",
    "    ]).reset_index(drop=True)\n",
    "    return sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T06:57:27.030981884Z",
     "start_time": "2023-05-07T06:57:26.957788453Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## preprocessing and helpers for classification/evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "categorical_fs = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "]\n",
    "\n",
    "education_order = [\n",
    "    'Preschool',\n",
    "    '1st-4th',\n",
    "    '5th-6th',\n",
    "    '7th-8th',\n",
    "    '9th',\n",
    "    '10th',\n",
    "    '11th',\n",
    "    '12th',\n",
    "    'HS-grad',\n",
    "    'Some-college',\n",
    "    'Assoc-acdm',\n",
    "    'Assoc-voc',\n",
    "    'Bachelors',\n",
    "    'Masters',\n",
    "    'Prof-school',\n",
    "    'Doctorate',\n",
    "]\n",
    "\n",
    "# get the columns in the correct order\n",
    "cols = np.concatenate([dataset.columns.copy(deep=True).drop(categorical_fs + ['income']), categorical_fs])\n",
    "cols_d = {c: i for i, c in enumerate(cols)}\n",
    "\n",
    "classifiers = [\n",
    "    [RandomForestClassifier, {'random_state': 2137}],\n",
    "    [DecisionTreeClassifier, {'random_state': 2137}],\n",
    "    [GaussianNB, {}],\n",
    "    [LogisticRegression, {}],\n",
    "    [KNeighborsClassifier, {}],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T06:57:28.990998384Z",
     "start_time": "2023-05-07T06:57:28.859690686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    X_all = dataset[features]\n",
    "    y_all = LabelEncoder().fit_transform(dataset['income'])\n",
    "\n",
    "    # encode categorical features\n",
    "    data_encoder = OrdinalEncoder().fit(X_all[categorical_fs])\n",
    "    X_categorical = data_encoder.transform(X_all[categorical_fs])\n",
    "\n",
    "    edu_encoder = OrdinalEncoder(categories=[education_order]).fit(X_all[['education']])\n",
    "    X_categorical[:, categorical_fs.index('education')] = edu_encoder.transform(X_all[['education']])[0]\n",
    "\n",
    "    # finally, the features\n",
    "    X_all = np.concatenate([X_all.drop(categorical_fs, axis=1), X_categorical], axis=1)\n",
    "\n",
    "    return X_all, y_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T06:57:29.458700514Z",
     "start_time": "2023-05-07T06:57:29.370643576Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def calculate_fairness(clf, X, y, protected, group=1, cls=1):\n",
    "    \"\"\"\n",
    "    :param protected: id/name of the protected attribute column\n",
    "    :param group: id of the protected group\n",
    "    :param cls: id of the positive class\n",
    "    :return: dictionary of fairness metrics for the given classifier's results\n",
    "    \"\"\"\n",
    "    y_pred = clf.predict(X)\n",
    "    # columns: protected_value, y_true, y_pred\n",
    "    labelled = np.concatenate([\n",
    "        X[:, protected].reshape(-1, 1),\n",
    "        y.reshape(-1, 1),\n",
    "        y_pred.reshape(-1, 1)\n",
    "    ], axis=1)\n",
    "\n",
    "    # calculate confusion matrices\n",
    "    cms = [None, None]\n",
    "\n",
    "    # y true/pred for the protected group\n",
    "    ys = labelled[labelled[:, 0] == group]\n",
    "    cms[0] = confusion_matrix(ys[:, 1], ys[:, 2], labels=[0, 1])\n",
    "    # ... and for the other (unprotected) group\n",
    "    ys = labelled[labelled[:, 0] != group]\n",
    "    cms[1] = confusion_matrix(ys[:, 1], ys[:, 2], labels=[0, 1])\n",
    "\n",
    "    # mj = majority - unprotected\n",
    "    # mr = minority - protected\n",
    "    mr, mj = group, 1 - group\n",
    "    pos, neg = cls, 1 - cls\n",
    "\n",
    "    # labels for the confusion matrix items\n",
    "    tn = (neg, neg)\n",
    "    fp = (neg, pos)\n",
    "    fn = (pos, neg)\n",
    "    tp = (pos, pos)\n",
    "\n",
    "    # calculate fairness metrics\n",
    "    fairness = dict()\n",
    "\n",
    "    # Accuracy Equality Difference\n",
    "    fairness['Accuracy Equality Difference'] = \\\n",
    "        (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
    "        (cms[mr].item(tp) + cms[mr].item(tn)) / cms[mr].sum()\n",
    "\n",
    "    # Equal Opportunity Difference: j_tpr - i_tpr\n",
    "    try:\n",
    "        fairness['Equal Opportunity Difference'] = \\\n",
    "            cms[mj].item(tp) / (cms[mj].item(tp) + cms[mj].item(fn)) - \\\n",
    "            cms[mr].item(tp) / (cms[mr].item(tp) + cms[mr].item(fn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Equal Opportunity Difference'] = np.nan\n",
    "\n",
    "    # Predictive Equality Difference: j_fpr - i_fpr\n",
    "    try:\n",
    "        fairness['Predictive Equality Difference'] = \\\n",
    "            cms[mj].item(fp) / (cms[mj].item(fp) + cms[mj].item(tn)) - \\\n",
    "            cms[mr].item(fp) / (cms[mr].item(fp) + cms[mr].item(tn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Predictive Equality Difference'] = np.nan\n",
    "\n",
    "    # Positive Predictive Parity Difference: j_ppv - i_ppv\n",
    "    try:\n",
    "        fairness['Positive Predictive Parity Difference'] = \\\n",
    "            cms[mj].item(tp) / (cms[mj].item(tp) + cms[mj].item(fp)) - \\\n",
    "            cms[mr].item(tp) / (cms[mr].item(tp) + cms[mr].item(fp))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Positive Predictive Parity Difference'] = np.nan\n",
    "\n",
    "    # Negative Predictive Parity Difference: j_npv - i_npv\n",
    "    try:\n",
    "        fairness['Negative Predictive Parity Difference'] = \\\n",
    "            cms[mj].item(tn) / (cms[mj].item(tn) + cms[mj].item(fn)) - \\\n",
    "            cms[mr].item(tn) / (cms[mr].item(tn) + cms[mr].item(fn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Negative Predictive Parity Difference'] = np.nan\n",
    "\n",
    "    fairness['Statistical Parity Difference'] = \\\n",
    "        (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
    "        (cms[mr].item(tp) + cms[mr].item(fp)) / cms[mr].sum()\n",
    "\n",
    "    return fairness"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T06:57:31.835148625Z",
     "start_time": "2023-05-07T06:57:31.832033454Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# group by metric\n",
    "def plot_fairness_gb_metric(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = ['\\n'.join([' '.join(f.split(\" \")[:2]), ' '.join(f.split(\" \")[2:])])\n",
    "               for f in fairness[list(fairness.keys())[0]].keys()]\n",
    "    xticks = np.arange(len(metrics))\n",
    "    width = 1. / (len(fairness.keys()) + 2)\n",
    "\n",
    "    for i, (clf, f) in enumerate(fairness.items()):\n",
    "        ax.bar(xticks + i * width, f.values(), width, label=clf.replace('Classifier', ''), color=colours[i])\n",
    "\n",
    "    ax.set_xticks(xticks + width * len(fairness.keys()) / 2, metrics, rotation=45)\n",
    "    ax.legend(ncols=1)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_fairness_gb_clf(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = fairness[list(fairness.keys())[0]].keys()\n",
    "    classifiers = [c.replace('Classifier', '') for c in fairness.keys()]\n",
    "    xticks = np.arange(len(classifiers))\n",
    "    width = 1. / (len(metrics) + 2)\n",
    "    shift = np.arange(len(metrics)) * width\n",
    "\n",
    "    for i, (clf, f) in enumerate(fairness.items()):\n",
    "        ax.bar(i + shift, f.values(), width, color=colours[:len(metrics)])\n",
    "    # ax.bar(xticks + shift, fairness, width)\n",
    "    ax.set_xticks(xticks + width * len(metrics) / 2, classifiers)\n",
    "    ax.legend(handles=[mpatches.Patch(color=c, label=m) for c, m in zip(colours, metrics)], ncol=1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T06:57:33.161897004Z",
     "start_time": "2023-05-07T06:57:33.083771079Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# setup\n",
    "holdout = ShuffleSplit(n_splits=50, test_size=.33, random_state=2137)\n",
    "SAMPLE_SIZE = 1100\n",
    "\n",
    "rs = [.01, .02, .05] + [round(x, 2) for x in np.arange(.1, 1., .1)] + [.95, .98, .99]\n",
    "ratios = [[.5, ir] for ir in rs] + [[gr, .5] for gr in rs]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T06:57:35.152527289Z",
     "start_time": "2023-05-07T06:57:34.995700999Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GR: 0.5, IR: 0.01\n",
      "GR: 0.5, IR: 0.02\n",
      "GR: 0.5, IR: 0.05\n",
      "GR: 0.5, IR: 0.1\n",
      "GR: 0.5, IR: 0.2\n",
      "GR: 0.5, IR: 0.3\n",
      "GR: 0.5, IR: 0.4\n",
      "GR: 0.5, IR: 0.5\n",
      "GR: 0.5, IR: 0.6\n",
      "GR: 0.5, IR: 0.7\n",
      "GR: 0.5, IR: 0.8\n",
      "GR: 0.5, IR: 0.9\n",
      "GR: 0.5, IR: 0.95\n",
      "GR: 0.5, IR: 0.98\n",
      "GR: 0.5, IR: 0.99\n",
      "GR: 0.01, IR: 0.5\n",
      "GR: 0.02, IR: 0.5\n",
      "GR: 0.05, IR: 0.5\n",
      "GR: 0.1, IR: 0.5\n",
      "GR: 0.2, IR: 0.5\n",
      "GR: 0.3, IR: 0.5\n",
      "GR: 0.4, IR: 0.5\n",
      "GR: 0.5, IR: 0.5\n",
      "GR: 0.6, IR: 0.5\n",
      "GR: 0.7, IR: 0.5\n",
      "GR: 0.8, IR: 0.5\n",
      "GR: 0.9, IR: 0.5\n",
      "GR: 0.95, IR: 0.5\n",
      "GR: 0.98, IR: 0.5\n",
      "GR: 0.99, IR: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9224/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_9224/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_9224/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_9224/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_9224/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_9224/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_9224/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_9224/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_9224/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_9224/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n"
     ]
    }
   ],
   "source": [
    "# calculations\n",
    "fairness_results = []\n",
    "results = []\n",
    "\n",
    "for gr, ir in ratios:\n",
    "    print(f'GR: {gr}, IR: {ir}')\n",
    "    swap_gr, swap_ir = False, False\n",
    "\n",
    "    df = split_data(dataset, SAMPLE_SIZE, gr, ir)\n",
    "    X_all, y_all = preprocess(df)\n",
    "\n",
    "    for i, (traini, testi) in enumerate(holdout.split(X_all)):\n",
    "        X_train, X_test = X_all[traini], X_all[testi]\n",
    "        y_train, y_test = y_all[traini], y_all[testi]\n",
    "\n",
    "        for clf, kwargs in classifiers:\n",
    "            pipe = make_pipeline(\n",
    "                KNNImputer(),\n",
    "                StandardScaler(),\n",
    "                clf(**kwargs)\n",
    "            ).fit(X_train, y_train)\n",
    "            f = calculate_fairness(pipe, X_test, y_test, cols_d['sex'], group=1-int(swap_gr), cls=1-int(swap_ir))\n",
    "\n",
    "            for p_metric in [roc_auc_score, geometric_mean_score, recall_score, f1_score]:\n",
    "                results.append([gr, ir, clf.__name__.replace('Classifier', ''), p_metric.__name__, p_metric(y_test, pipe.predict(X_test), labels=[0, 1])])\n",
    "\n",
    "            for metric, value in f.items():\n",
    "                fairness_results.append([gr, ir, clf.__name__.replace('Classifier', ''), metric, value])\n",
    "\n",
    "results_cv = pd.DataFrame(results, columns=['gr', 'ir', 'clf', 'metric', 'value'])\n",
    "fairness_results_cv = pd.DataFrame(fairness_results, columns=['gr', 'ir', 'clf', 'metric', 'value'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T07:12:34.673618943Z",
     "start_time": "2023-05-07T06:57:47.932147379Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pickle the results\n",
    "\n",
    "with open(os.path.join('out', 'fairness_results_cv.pkl'), 'wb') as f:\n",
    "    pickle.dump(fairness_results_cv, f)\n",
    "\n",
    "with open(os.path.join('out', 'clf_results_cv.pkl'), 'wb') as f:\n",
    "    pickle.dump(results_cv, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # unpickle - for reusing the results\n",
    "#\n",
    "# with open(os.path.join('out', 'fairness_results_cv.pkl'), 'rb') as f:\n",
    "#     fairness_results_cv = pickle.load(f)\n",
    "#\n",
    "# with open(os.path.join('out', 'clf_results_cv.pkl'), 'rb') as f:\n",
    "#     results_cv = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Line graph: `fairness(ratio)`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def plot_line(fairness: pd.DataFrame, metric: str, ratio_type: str, fill='std', ylim=(-.5, .5)):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(ratio_type.upper())\n",
    "\n",
    "    metrics = fairness['metric'].unique()\n",
    "    clfs = fairness['clf'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "    mean, stdev, err = {}, {}, {}\n",
    "\n",
    "    for r in ratios:\n",
    "        for clf in clfs:\n",
    "            subset = fairness[\n",
    "                (fairness[ratio_type] == r) &\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric) &\n",
    "                fairness['value'].notna()\n",
    "            ]\n",
    "            mean[(r, clf)] = subset['value'].mean(skipna=True)\n",
    "            stdev[(r, clf)] = subset['value'].std(skipna=True)\n",
    "            err[(r, clf)] = scipy.stats.sem(subset['value'], nan_policy='omit')\n",
    "\n",
    "    ax.axhline(0, color='black', linestyle='--', alpha=.3)\n",
    "\n",
    "    for i, clf in enumerate(clfs):\n",
    "        ax.plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[i], marker='o')\n",
    "        if fill == 'err':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "        elif fill == 'std':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "\n",
    "    ax.legend(loc=9)\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "    # workaround to keep the x tick labels readable\n",
    "    ratios_ticks = ['0.01', '  \\n0.02',\n",
    "                    '0.05', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '0.95',\n",
    "                    '0.98\\n  ', '0.99']\n",
    "\n",
    "    ax.set_xticks(ratios, ratios_ticks, rotation=90)\n",
    "    ax.set_xlim(0, 1)\n",
    "    if ylim:\n",
    "        ax.set_ylim(*ylim)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T20:27:06.060023140Z",
     "start_time": "2023-05-04T20:27:06.011924008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n"
     ]
    }
   ],
   "source": [
    "for fill in ('std', 'err'):\n",
    "    subdir = f'line_{fill}'\n",
    "    os.makedirs(os.path.join(plots_dir, subdir), exist_ok=True)\n",
    "\n",
    "    for ratio_type, ylim in [\n",
    "        ('ir', (-.9, .9)),\n",
    "        ('gr', (-.9, .9)),\n",
    "        ]:\n",
    "        for metric in fairness_results_cv['metric'].unique():\n",
    "            fig = plot_line(fairness_results_cv, metric, ratio_type, ylim=ylim, fill=fill)\n",
    "            fig.savefig(os.path.join(plots_dir, subdir, f'fairness_line_{ratio_type}_{metric}.svg'))\n",
    "            plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T20:27:23.969544262Z",
     "start_time": "2023-05-04T20:27:06.163936301Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### plot the absolute value of fairness metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def plot_line_abs(fairness: pd.DataFrame, metric: str, ratio_type: str, fill='std', ylim=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(ratio_type.upper())\n",
    "\n",
    "    metrics = fairness['metric'].unique()\n",
    "    clfs = fairness['clf'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "    mean, stdev, err = {}, {}, {}\n",
    "\n",
    "    for r in ratios:\n",
    "        for clf in clfs:\n",
    "            subset = fairness[\n",
    "                (fairness[ratio_type] == r) &\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric) &\n",
    "                fairness['value'].notna()\n",
    "                ]\n",
    "            mean[(r, clf)] = subset['value'].abs().mean(skipna=True)\n",
    "            stdev[(r, clf)] = subset['value'].abs().std(skipna=True)\n",
    "            err[(r, clf)] = scipy.stats.sem(subset['value'].abs(), nan_policy='omit')\n",
    "\n",
    "    for i, clf in enumerate(clfs):\n",
    "        ax.plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[i], marker='o')\n",
    "        if fill == 'err':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "        elif fill == 'std':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "\n",
    "    ax.legend(loc=9)\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(ratios, ratios, rotation=90)\n",
    "    ax.set_xlim(0, 1)\n",
    "    if ylim:\n",
    "        ax.set_ylim(*ylim)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:09.579591Z",
     "end_time": "2023-05-03T14:54:09.591158Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "for fill in ('std', 'err'):\n",
    "    subdir = f'line_abs_{fill}'\n",
    "    os.makedirs(os.path.join(plots_dir, subdir), exist_ok=True)\n",
    "\n",
    "    for ratio_type in ['ir', 'gr']:\n",
    "        for metric in fairness_results_cv['metric'].unique():\n",
    "            fig = plot_line_abs(fairness_results_cv, metric, ratio_type, ylim=(0, .6), fill=fill)\n",
    "            fig.savefig(os.path.join(plots_dir, subdir, f'fairness_line_{ratio_type}_{metric}_{fill}_abs_rh.svg'))\n",
    "            plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:09.579857Z",
     "end_time": "2023-05-03T14:54:28.907114Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### plot nan count\n",
    "\n",
    "check how many results are undefined for the metrics and ratios"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def plot_nan(fairness, ratio_type, clfs=None, metrics=None, ylim=None):\n",
    "    if clfs is None:\n",
    "        clfs = fairness['clf'].unique()\n",
    "    if metrics is None:\n",
    "        metrics = fairness['metric'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(metrics) - 1) // 2 + 1,\n",
    "                           sharex=True, sharey=True,\n",
    "                           figsize=(16, 9))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax[i % 2, i // 2].set_title(metric)\n",
    "        ax[i % 2, i // 2].set_ylabel('NaN probability')\n",
    "        ax[i % 2, i // 2].set_xlabel(ratio_type.upper())\n",
    "        ax[i % 2, i // 2].yaxis.set_major_formatter(PercentFormatter(1))\n",
    "        ax[i % 2, i // 2].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "        for j, clf in enumerate(clfs):\n",
    "            subset = fairness[\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric)\n",
    "                ]\n",
    "            counts = subset.groupby(ratio_type)['value'].apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "            ax[i % 2, i // 2].plot(ratios, counts,\n",
    "                                   label=clf, color=colours[j], marker='o', alpha=.6)\n",
    "\n",
    "    if ylim:\n",
    "        ax[0, 0].set_ylim(*ylim)\n",
    "    else:\n",
    "        ax[0, 0].set_ylim(0, ax[0, 0].get_ylim()[1] * 1.1)\n",
    "    ax[0, 0].set_xlim(0, 1)\n",
    "    ax[0, 0].legend(loc=0)\n",
    "\n",
    "    return fig\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:35.196443Z",
     "end_time": "2023-05-03T14:54:35.203882Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "for ratio_type in ['ir', 'gr']:\n",
    "    fig = plot_nan(fairness_results_cv, ratio_type,\n",
    "                   metrics=[\n",
    "                       'Accuracy Equality Difference',\n",
    "                       'Statistical Parity Difference',\n",
    "                       'Equal Opportunity Difference',\n",
    "                       'Predictive Equality Difference',\n",
    "                       'Positive Predictive Parity Difference',\n",
    "                       'Negative Predictive Parity Difference',\n",
    "                   ])\n",
    "    fig.savefig(os.path.join(plots_dir, f'fairness_nan_{ratio_type}.svg'))\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:37.276486Z",
     "end_time": "2023-05-03T14:54:38.163777Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot all metrics together"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def plot_line_all(fairness: pd.DataFrame, metrics: list[str], ratio_type: str, fill='std', ylim=(-.5, .5)):\n",
    "    fig, axs = plt.subplots(\n",
    "        (len(metrics) - 1) // 2 + 1, 2,\n",
    "        sharex=True, sharey=True,\n",
    "        figsize=(14, 10)\n",
    "    )\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        axs[i // 2, i % 2].set_ylabel(metric.replace('Difference', ''))\n",
    "\n",
    "        metrics = fairness['metric'].unique()\n",
    "        clfs = fairness['clf'].unique()\n",
    "        ratios = sorted(fairness[ratio_type].unique())\n",
    "        other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "        mean, stdev, err = {}, {}, {}\n",
    "\n",
    "        for r in ratios:\n",
    "            for clf in clfs:\n",
    "                subset = fairness[\n",
    "                    (fairness[ratio_type] == r) &\n",
    "                    (fairness['clf'] == clf) &\n",
    "                    (fairness[other_ratio] == .5) &\n",
    "                    (fairness['metric'] == metric) &\n",
    "                    fairness['value'].notna()\n",
    "                    ]\n",
    "                mean[(r, clf)] = subset['value'].mean(skipna=True)\n",
    "                stdev[(r, clf)] = subset['value'].std(skipna=True)\n",
    "                err[(r, clf)] = scipy.stats.sem(subset['value'], nan_policy='omit')\n",
    "\n",
    "        axs[i // 2, i % 2].axhline(0, color='black', linestyle='--', alpha=.9, lw=1)\n",
    "\n",
    "        for j, clf in enumerate(clfs):\n",
    "            axs[i // 2, i % 2].plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[j], marker='o', lw=1, alpha=.85)\n",
    "            if fill == 'err':\n",
    "                axs[i // 2, i % 2].fill_between(ratios,\n",
    "                                [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                                [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                                alpha=.15, color=colours[j])\n",
    "            elif fill == 'std':\n",
    "                axs[i // 2, i % 2].fill_between(ratios,\n",
    "                                [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                                [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                                alpha=.15, color=colours[j])\n",
    "\n",
    "        ratios_ticks = ['0.01\\n', '0.02',\n",
    "                        '0.05', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '0.95',\n",
    "                        '0.98', '\\n0.99']\n",
    "\n",
    "        axs[i // 2, i % 2].spines[['top', 'right']].set_visible(False)\n",
    "        axs[i // 2, i % 2].set_xticks(ratios, ratios_ticks, rotation=90)\n",
    "        axs[i // 2, i % 2].set_xlim(0, 1)\n",
    "        if i // 2 == 2:\n",
    "            axs[i // 2, i % 2].set_xlabel(x_labels[ratio_type])\n",
    "        if ylim:\n",
    "            axs[i // 2, i % 2].set_ylim(*ylim)\n",
    "\n",
    "    axs[0, 0].legend(loc=1,\n",
    "                     ncols=3)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T21:09:22.314324240Z",
     "start_time": "2023-05-04T21:09:22.271433141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ratio_type in ['ir', 'gr']:\n",
    "    fig = plot_line_all(fairness_results_cv, [\n",
    "        'Accuracy Equality Difference',\n",
    "        'Statistical Parity Difference',\n",
    "        'Equal Opportunity Difference',\n",
    "        'Predictive Equality Difference',\n",
    "        'Positive Predictive Parity Difference',\n",
    "        'Negative Predictive Parity Difference',\n",
    "    ], ratio_type, fill='std', ylim=(-.9, .9))\n",
    "    fig.savefig(os.path.join(plots_dir, f'fairness_all_{ratio_type}.svg'))\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table with classification metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f2d480cca30>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv.groupby(['clf', 'ir', 'gr'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:43:33.130602900Z",
     "start_time": "2023-05-06T20:43:33.082896962Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
