{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adult Dataset, aka Census income\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/adult"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "# colour scheme inspired by https://personal.sron.nl/~pault/\n",
    "colours = ['#EE7733', '#33BBEE', '#EE3377', '#888888', '#009988',]\n",
    "\n",
    "x_labels = {\n",
    "    'gr': 'Protected group ratio (GR)',\n",
    "    'ir': 'Imbalance ratio (IR)',\n",
    "}\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 13\n",
    "BIGGER_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:21:16.860779075Z",
     "start_time": "2023-05-06T20:21:16.848614347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:07:53.096067820Z",
     "start_time": "2023-05-06T20:07:52.912135097Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44730/1575989903.py:17: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dataset = pd.read_csv('data/adult.data', sep=', ', na_values=['?', ' ?'],\n"
     ]
    },
    {
     "data": {
      "text/plain": "   age         workclass  education  education-num      marital-status  \\\n0   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n1   38           Private    HS-grad              9            Divorced   \n2   53           Private       11th              7  Married-civ-spouse   \n3   28           Private  Bachelors             13  Married-civ-spouse   \n4   37           Private    Masters             14  Married-civ-spouse   \n\n          occupation   relationship   race     sex  capital-gain  \\\n0    Exec-managerial        Husband  White    Male             0   \n1  Handlers-cleaners  Not-in-family  White    Male             0   \n2  Handlers-cleaners        Husband  Black    Male             0   \n3     Prof-specialty           Wife  Black  Female             0   \n4    Exec-managerial           Wife  White  Female             0   \n\n   capital-loss  hours-per-week native-country income  \n0             0              13  United-States  <=50K  \n1             0              40  United-States  <=50K  \n2             0              40  United-States  <=50K  \n3             0              40           Cuba  <=50K  \n4             0              40  United-States  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37</td>\n      <td>Private</td>\n      <td>Masters</td>\n      <td>14</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',       # removed\n",
    "    'education',    # sorted later on\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "]\n",
    "dataset = pd.read_csv('data/adult.data', sep=', ', na_values=['?', ' ?'],\n",
    "                      header=0, names=features + ['income'])\n",
    "dataset.drop(columns=['fnlwgt'], inplace=True)\n",
    "features.remove('fnlwgt')\n",
    "\n",
    "plots_dir = os.path.join('out', 'plots', 'case_study', 'census_income')\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Group and class sizes\n",
    "\n",
    "groups: sex\n",
    "class: income (1: >=50k)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32560, 14)\n",
      "10771\n",
      "21789\n",
      "24719\n",
      "7841\n",
      "\n",
      "\n",
      "\n",
      "F 0: 9592\n",
      "F 1: 1179\n",
      "M 0: 15127\n",
      "M 1: 6662\n"
     ]
    }
   ],
   "source": [
    "# decide on the split size\n",
    "\n",
    "print(\n",
    "    dataset.shape,\n",
    "    dataset[dataset['sex'] == 'Female'].shape[0],\n",
    "    dataset[dataset['sex'] != 'Female'].shape[0],\n",
    "    dataset[dataset['income'] != '>50K'].shape[0],\n",
    "    dataset[dataset['income'] == '>50K'].shape[0],\n",
    "    sep='\\n'\n",
    ")\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# check set intersections\n",
    "conditions_g = [\n",
    "    (dataset['sex'] == 'Female', 'F'),\n",
    "    (dataset['sex'] == 'Male', 'M'),\n",
    "]\n",
    "\n",
    "conditions_i = [\n",
    "    (dataset['income'] == '<=50K', '0'),\n",
    "    (dataset['income'] == '>50K', '1'),\n",
    "]\n",
    "\n",
    "for c_g, g in conditions_g:\n",
    "    for c_i, i in conditions_i:\n",
    "        print(f'{g} {i}: {dataset[c_g & c_i].shape[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:09:43.827667Z",
     "end_time": "2023-05-03T13:09:43.827896Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### splitting data\n",
    "\n",
    "the split is proportional to group/class sizes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "n = dataset.shape[0]\n",
    "gr = ir = .5\n",
    "\n",
    "# [majority, minority]\n",
    "sex = ['Male', 'Female']\n",
    "income = ['<=50K', '>50K']\n",
    "\n",
    "\n",
    "def split_data(df, n, gr, ir):\n",
    "    \"\"\"\n",
    "    :param df: original data\n",
    "    :param n: final size of the sample\n",
    "    :return: the sample\n",
    "    \"\"\"\n",
    "    data_len = df.shape[0]\n",
    "    # set ratios of sex and income\n",
    "    f0 = round(n * gr * (1 - ir))\n",
    "    f1 = round(n * gr * ir)\n",
    "    m0 = round(n * (1 - gr) * (1 - ir))\n",
    "    m1 = round(n * (1 - gr) * ir)\n",
    "\n",
    "    sample = pd.concat([\n",
    "        df[(df['sex'] == sex[1]) & (df['income'] == income[0])].sample(n=int(f0), random_state=2137),\n",
    "        df[(df['sex'] == sex[1]) & (df['income'] == income[1])].sample(n=int(f1), random_state=2137),\n",
    "        df[(df['sex'] == sex[0]) & (df['income'] == income[0])].sample(n=int(m0), random_state=2137),\n",
    "        df[(df['sex'] == sex[0]) & (df['income'] == income[1])].sample(n=int(m1), random_state=2137),\n",
    "    ]).reset_index(drop=True)\n",
    "    return sample\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:11:09.531539831Z",
     "start_time": "2023-05-06T20:11:09.525835763Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## preprocessing and helpers for classification/evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "categorical_fs = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "]\n",
    "\n",
    "education_order = [\n",
    "    'Preschool',\n",
    "    '1st-4th',\n",
    "    '5th-6th',\n",
    "    '7th-8th',\n",
    "    '9th',\n",
    "    '10th',\n",
    "    '11th',\n",
    "    '12th',\n",
    "    'HS-grad',\n",
    "    'Some-college',\n",
    "    'Assoc-acdm',\n",
    "    'Assoc-voc',\n",
    "    'Bachelors',\n",
    "    'Masters',\n",
    "    'Prof-school',\n",
    "    'Doctorate',\n",
    "]\n",
    "\n",
    "# get the columns in the correct order\n",
    "cols = np.concatenate([dataset.columns.copy(deep=True).drop(categorical_fs + ['income']), categorical_fs])\n",
    "cols_d = {c: i for i, c in enumerate(cols)}\n",
    "\n",
    "classifiers = [\n",
    "    [RandomForestClassifier, {'random_state': 2137}],\n",
    "    [DecisionTreeClassifier, {'random_state': 2137}],\n",
    "    [GaussianNB, {}],\n",
    "    [LogisticRegression, {}],\n",
    "    [KNeighborsClassifier, {}],\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:11:59.197921864Z",
     "start_time": "2023-05-06T20:11:59.186940448Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    X_all = dataset[features]\n",
    "    y_all = LabelEncoder().fit_transform(dataset['income'])\n",
    "\n",
    "    # encode categorical features\n",
    "    data_encoder = OrdinalEncoder().fit(X_all[categorical_fs])\n",
    "    X_categorical = data_encoder.transform(X_all[categorical_fs])\n",
    "\n",
    "    edu_encoder = OrdinalEncoder(categories=[education_order]).fit(X_all[['education']])\n",
    "    X_categorical[:, categorical_fs.index('education')] = edu_encoder.transform(X_all[['education']])[0]\n",
    "\n",
    "    # finally, the features\n",
    "    X_all = np.concatenate([X_all.drop(categorical_fs, axis=1), X_categorical], axis=1)\n",
    "    # X_all[:5]\n",
    "\n",
    "    return X_all, y_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:12:05.418699360Z",
     "start_time": "2023-05-06T20:12:05.413028704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def calculate_fairness(clf, X, y, protected, group=1, cls=1):\n",
    "    \"\"\"\n",
    "    :param protected: id/name of the protected attribute column\n",
    "    :param group: id of the protected group\n",
    "    :param cls: id of the positive class\n",
    "    :return: dictionary of fairness metrics for the given classifier's results\n",
    "    \"\"\"\n",
    "    y_pred = clf.predict(X)\n",
    "    # columns: protected_value, y_true, y_pred\n",
    "    labelled = np.concatenate([\n",
    "        X[:, protected].reshape(-1, 1),\n",
    "        y.reshape(-1, 1),\n",
    "        y_pred.reshape(-1, 1)\n",
    "    ], axis=1)\n",
    "\n",
    "    # calculate confusion matrices\n",
    "    cms = [None, None]\n",
    "\n",
    "    # y true/pred for the protected group\n",
    "    ys = labelled[labelled[:, 0] == group]\n",
    "    cms[0] = confusion_matrix(ys[:, 1], ys[:, 2], labels=[0, 1])\n",
    "    # ... and for the other (unprotected) group\n",
    "    ys = labelled[labelled[:, 0] != group]\n",
    "    cms[1] = confusion_matrix(ys[:, 1], ys[:, 2], labels=[0, 1])\n",
    "\n",
    "    # mj = majority - unprotected\n",
    "    # mr = minority - protected\n",
    "    mr, mj = group, 1 - group\n",
    "    pos, neg = cls, 1 - cls\n",
    "\n",
    "    # labels for the confusion matrix items\n",
    "    tn = (neg, neg)\n",
    "    fp = (neg, pos)\n",
    "    fn = (pos, neg)\n",
    "    tp = (pos, pos)\n",
    "\n",
    "    # calculate fairness metrics\n",
    "    fairness = dict()\n",
    "\n",
    "    # Accuracy Equality Difference\n",
    "    fairness['Accuracy Equality Difference'] = \\\n",
    "        (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
    "        (cms[mr].item(tp) + cms[mr].item(tn)) / cms[mr].sum()\n",
    "\n",
    "    # Equal Opportunity Difference: j_tpr - i_tpr\n",
    "    try:\n",
    "        fairness['Equal Opportunity Difference'] = \\\n",
    "            cms[mj].item(tp) / (cms[mj].item(tp) + cms[mj].item(fn)) - \\\n",
    "            cms[mr].item(tp) / (cms[mr].item(tp) + cms[mr].item(fn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Equal Opportunity Difference'] = np.nan\n",
    "\n",
    "    # Predictive Equality Difference: j_fpr - i_fpr\n",
    "    try:\n",
    "        fairness['Predictive Equality Difference'] = \\\n",
    "            cms[mj].item(fp) / (cms[mj].item(fp) + cms[mj].item(tn)) - \\\n",
    "            cms[mr].item(fp) / (cms[mr].item(fp) + cms[mr].item(tn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Predictive Equality Difference'] = np.nan\n",
    "\n",
    "    # Positive Predictive Parity Difference: j_ppv - i_ppv\n",
    "    try:\n",
    "        fairness['Positive Predictive Parity Difference'] = \\\n",
    "            cms[mj].item(tp) / (cms[mj].item(tp) + cms[mj].item(fp)) - \\\n",
    "            cms[mr].item(tp) / (cms[mr].item(tp) + cms[mr].item(fp))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Positive Predictive Parity Difference'] = np.nan\n",
    "\n",
    "    # Negative Predictive Parity Difference: j_npv - i_npv\n",
    "    try:\n",
    "        fairness['Negative Predictive Parity Difference'] = \\\n",
    "            cms[mj].item(tn) / (cms[mj].item(tn) + cms[mj].item(fn)) - \\\n",
    "            cms[mr].item(tn) / (cms[mr].item(tn) + cms[mr].item(fn))\n",
    "    except ZeroDivisionError:\n",
    "        fairness['Negative Predictive Parity Difference'] = np.nan\n",
    "\n",
    "    fairness['Statistical Parity Difference'] = \\\n",
    "        (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
    "        (cms[mr].item(tp) + cms[mr].item(fp)) / cms[mr].sum()\n",
    "\n",
    "    return fairness"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:12:17.640512328Z",
     "start_time": "2023-05-06T20:12:17.638425870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# group by metric\n",
    "def plot_fairness_gb_metric(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = ['\\n'.join([' '.join(f.split(\" \")[:2]), ' '.join(f.split(\" \")[2:])])\n",
    "               for f in fairness[list(fairness.keys())[0]].keys()]\n",
    "    xticks = np.arange(len(metrics))\n",
    "    width = 1. / (len(fairness.keys()) + 2)\n",
    "\n",
    "    for i, (clf, f) in enumerate(fairness.items()):\n",
    "        ax.bar(xticks + i * width, f.values(), width, label=clf.replace('Classifier', ''), color=colours[i])\n",
    "\n",
    "    ax.set_xticks(xticks + width * len(fairness.keys()) / 2, metrics, rotation=45)\n",
    "    ax.legend(ncols=1)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_fairness_gb_clf(fairness, gr, ir):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.set_title(f'Fairness metrics for different classifiers; GR = {gr}, IR = {ir}')\n",
    "    ax.set_ylabel('Fairness metric value')\n",
    "\n",
    "    metrics = fairness[list(fairness.keys())[0]].keys()\n",
    "    classifiers = [c.replace('Classifier', '') for c in fairness.keys()]\n",
    "    xticks = np.arange(len(classifiers))\n",
    "    width = 1. / (len(metrics) + 2)\n",
    "    shift = np.arange(len(metrics)) * width\n",
    "\n",
    "    for i, (clf, f) in enumerate(fairness.items()):\n",
    "        ax.bar(i + shift, f.values(), width, color=colours[:len(metrics)])\n",
    "    # ax.bar(xticks + shift, fairness, width)\n",
    "    ax.set_xticks(xticks + width * len(metrics) / 2, classifiers)\n",
    "    ax.legend(handles=[mpatches.Patch(color=c, label=m) for c, m in zip(colours, metrics)], ncol=1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:12:45.604746187Z",
     "start_time": "2023-05-06T20:12:45.561382789Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Line graph: `fairness(ratio)`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# setup\n",
    "holdout = ShuffleSplit(n_splits=50, test_size=.33, random_state=2137)\n",
    "SAMPLE_SIZE = 1100\n",
    "\n",
    "rs = [.01, .02, .05] + [round(x, 2) for x in np.arange(.1, 1., .1)] + [.95, .98, .99]\n",
    "ratios = [[.5, ir] for ir in rs] + [[gr, .5] for gr in rs]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:13:12.268893295Z",
     "start_time": "2023-05-06T20:13:12.261179384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GR: 0.5, IR: 0.01\n",
      "GR: 0.5, IR: 0.02\n",
      "GR: 0.5, IR: 0.05\n",
      "GR: 0.5, IR: 0.1\n",
      "GR: 0.5, IR: 0.2\n",
      "GR: 0.5, IR: 0.3\n",
      "GR: 0.5, IR: 0.4\n",
      "GR: 0.5, IR: 0.5\n",
      "GR: 0.5, IR: 0.6\n",
      "GR: 0.5, IR: 0.7\n",
      "GR: 0.5, IR: 0.8\n",
      "GR: 0.5, IR: 0.9\n",
      "GR: 0.5, IR: 0.95\n",
      "GR: 0.5, IR: 0.98\n",
      "GR: 0.5, IR: 0.99\n",
      "GR: 0.01, IR: 0.5\n",
      "GR: 0.02, IR: 0.5\n",
      "GR: 0.05, IR: 0.5\n",
      "GR: 0.1, IR: 0.5\n",
      "GR: 0.2, IR: 0.5\n",
      "GR: 0.3, IR: 0.5\n",
      "GR: 0.4, IR: 0.5\n",
      "GR: 0.5, IR: 0.5\n",
      "GR: 0.6, IR: 0.5\n",
      "GR: 0.7, IR: 0.5\n",
      "GR: 0.8, IR: 0.5\n",
      "GR: 0.9, IR: 0.5\n",
      "GR: 0.95, IR: 0.5\n",
      "GR: 0.98, IR: 0.5\n",
      "GR: 0.99, IR: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44730/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_44730/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_44730/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_44730/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_44730/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_44730/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_44730/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_44730/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_44730/697211784.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(tn)) / cms[mj].sum() - \\\n",
      "/tmp/ipykernel_44730/697211784.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (cms[mj].item(tp) + cms[mj].item(fp)) / cms[mj].sum() - \\\n"
     ]
    }
   ],
   "source": [
    "# calculations\n",
    "fairness_results = []\n",
    "results = []\n",
    "\n",
    "for gr, ir in ratios:\n",
    "    print(f'GR: {gr}, IR: {ir}')\n",
    "    swap_gr, swap_ir = False, False\n",
    "\n",
    "    df = split_data(dataset, SAMPLE_SIZE, gr, ir)\n",
    "    X_all, y_all = preprocess(df)\n",
    "\n",
    "    for i, (traini, testi) in enumerate(holdout.split(X_all)):\n",
    "        X_train, X_test = X_all[traini], X_all[testi]\n",
    "        y_train, y_test = y_all[traini], y_all[testi]\n",
    "\n",
    "        for clf, kwargs in classifiers:\n",
    "            pipe = make_pipeline(\n",
    "                KNNImputer(),\n",
    "                StandardScaler(),\n",
    "                clf(**kwargs)\n",
    "            ).fit(X_train, y_train)\n",
    "            f = calculate_fairness(pipe, X_test, y_test, cols_d['sex'], group=1-int(swap_gr), cls=1-int(swap_ir))\n",
    "\n",
    "            for p_metric in [roc_auc_score, geometric_mean_score, recall_score, f1_score]:\n",
    "                results.append([gr, ir, clf.__name__.replace('Classifier', ''), p_metric.__name__, p_metric(y_test, pipe.predict(X_test), labels=[0, 1])])\n",
    "\n",
    "            for metric, value in f.items():\n",
    "                fairness_results.append([gr, ir, clf.__name__.replace('Classifier', ''), metric, value])\n",
    "\n",
    "results_cv = pd.DataFrame(results, columns=['gr', 'ir', 'clf', 'metric', 'value'])\n",
    "fairness_results_cv = pd.DataFrame(fairness_results, columns=['gr', 'ir', 'clf', 'metric', 'value'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:37:01.981705750Z",
     "start_time": "2023-05-06T20:24:40.086622875Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "    gr    ir           clf                metric     value\n0  0.5  0.01  RandomForest         roc_auc_score  0.500000\n1  0.5  0.01  RandomForest  geometric_mean_score  0.000000\n2  0.5  0.01  RandomForest          recall_score  0.000000\n3  0.5  0.01  RandomForest              f1_score  0.000000\n4  0.5  0.01  DecisionTree         roc_auc_score  0.665266",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gr</th>\n      <th>ir</th>\n      <th>clf</th>\n      <th>metric</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>roc_auc_score</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>geometric_mean_score</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>recall_score</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>f1_score</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>DecisionTree</td>\n      <td>roc_auc_score</td>\n      <td>0.665266</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:37:01.995877536Z",
     "start_time": "2023-05-06T20:37:01.982191208Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "    gr    ir           clf                                 metric     value\n0  0.5  0.01  RandomForest           Accuracy Equality Difference -0.011846\n1  0.5  0.01  RandomForest           Equal Opportunity Difference  0.000000\n2  0.5  0.01  RandomForest         Predictive Equality Difference  0.000000\n3  0.5  0.01  RandomForest  Positive Predictive Parity Difference       NaN\n4  0.5  0.01  RandomForest  Negative Predictive Parity Difference -0.011846",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gr</th>\n      <th>ir</th>\n      <th>clf</th>\n      <th>metric</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Accuracy Equality Difference</td>\n      <td>-0.011846</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Equal Opportunity Difference</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Predictive Equality Difference</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Positive Predictive Parity Difference</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>0.01</td>\n      <td>RandomForest</td>\n      <td>Negative Predictive Parity Difference</td>\n      <td>-0.011846</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_results_cv.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:37:02.025612977Z",
     "start_time": "2023-05-06T20:37:01.993622270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def plot_line(fairness: pd.DataFrame, metric: str, ratio_type: str, fill='std', ylim=(-.5, .5)):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(ratio_type.upper())\n",
    "\n",
    "    metrics = fairness['metric'].unique()\n",
    "    clfs = fairness['clf'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "    mean, stdev, err = {}, {}, {}\n",
    "\n",
    "    for r in ratios:\n",
    "        for clf in clfs:\n",
    "            subset = fairness[\n",
    "                (fairness[ratio_type] == r) &\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric) &\n",
    "                fairness['value'].notna()\n",
    "            ]\n",
    "            mean[(r, clf)] = subset['value'].mean(skipna=True)\n",
    "            stdev[(r, clf)] = subset['value'].std(skipna=True)\n",
    "            err[(r, clf)] = scipy.stats.sem(subset['value'], nan_policy='omit')\n",
    "\n",
    "    ax.axhline(0, color='black', linestyle='--', alpha=.3)\n",
    "\n",
    "    for i, clf in enumerate(clfs):\n",
    "        ax.plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[i], marker='o')\n",
    "        if fill == 'err':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "        elif fill == 'std':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "\n",
    "    ax.legend(loc=9)\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "    # workaround to keep the x tick labels readable\n",
    "    ratios_ticks = ['0.01',\n",
    "                    '  \\n0.02',\n",
    "                    '0.05',\n",
    "                    '0.1',\n",
    "                    '0.2',\n",
    "                    '0.3',\n",
    "                    '0.4',\n",
    "                    '0.5',\n",
    "                    '0.6',\n",
    "                    '0.7',\n",
    "                    '0.8',\n",
    "                    '0.9',\n",
    "                    '0.95',\n",
    "                    '0.98\\n  ',\n",
    "                    '0.99']\n",
    "\n",
    "    ax.set_xticks(ratios, ratios_ticks, rotation=90)\n",
    "    ax.set_xlim(0, 1)\n",
    "    if ylim:\n",
    "        ax.set_ylim(*ylim)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T20:27:06.060023140Z",
     "start_time": "2023-05-04T20:27:06.011924008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/jstachowiak/anaconda3/envs/mgr/lib/python3.10/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n"
     ]
    }
   ],
   "source": [
    "for fill in ('std', 'err'):\n",
    "    subdir = f'line_{fill}'\n",
    "    os.makedirs(os.path.join(plots_dir, subdir), exist_ok=True)\n",
    "\n",
    "    for ratio_type, ylim in [\n",
    "        ('ir', (-.9, .9)),\n",
    "        ('gr', (-.9, .9)),\n",
    "        ]:\n",
    "        for metric in fairness_results_cv['metric'].unique():\n",
    "            fig = plot_line(fairness_results_cv, metric, ratio_type, ylim=ylim, fill=fill)\n",
    "            fig.savefig(os.path.join(plots_dir, subdir, f'fairness_line_{ratio_type}_{metric}.svg'))\n",
    "            plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T20:27:23.969544262Z",
     "start_time": "2023-05-04T20:27:06.163936301Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### plot absolute value of fairness metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def plot_line_abs(fairness: pd.DataFrame, metric: str, ratio_type: str, fill='std', ylim=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # ax.set_title(f'Value of *{metric}* for different {ratio_type.upper()}')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(ratio_type.upper())\n",
    "\n",
    "    metrics = fairness['metric'].unique()\n",
    "    clfs = fairness['clf'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "    mean, stdev, err = {}, {}, {}\n",
    "\n",
    "    for r in ratios:\n",
    "        for clf in clfs:\n",
    "            subset = fairness[\n",
    "                (fairness[ratio_type] == r) &\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric) &\n",
    "                fairness['value'].notna()\n",
    "                ]\n",
    "            mean[(r, clf)] = subset['value'].abs().mean(skipna=True)\n",
    "            stdev[(r, clf)] = subset['value'].abs().std(skipna=True)\n",
    "            err[(r, clf)] = scipy.stats.sem(subset['value'].abs(), nan_policy='omit')\n",
    "\n",
    "    for i, clf in enumerate(clfs):\n",
    "        ax.plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[i], marker='o')\n",
    "        if fill == 'err':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "        elif fill == 'std':\n",
    "            ax.fill_between(ratios,\n",
    "                            [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                            [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                            alpha=.15, color=colours[i])\n",
    "\n",
    "    ax.legend(loc=9)\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(ratios, ratios, rotation=90)\n",
    "    ax.set_xlim(0, 1)\n",
    "    if ylim:\n",
    "        ax.set_ylim(*ylim)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:09.579591Z",
     "end_time": "2023-05-03T14:54:09.591158Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "for fill in ('std', 'err'):\n",
    "    subdir = f'line_abs_{fill}'\n",
    "    os.makedirs(os.path.join(plots_dir, subdir), exist_ok=True)\n",
    "\n",
    "    for ratio_type in ['ir', 'gr']:\n",
    "        for metric in fairness_results_cv['metric'].unique():\n",
    "            fig = plot_line_abs(fairness_results_cv, metric, ratio_type, ylim=(0, .6), fill=fill)\n",
    "            fig.savefig(os.path.join(plots_dir, subdir, f'fairness_line_{ratio_type}_{metric}_{fill}_abs_rh.svg'))\n",
    "            plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:09.579857Z",
     "end_time": "2023-05-03T14:54:28.907114Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### count NaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "metric                                 clf               \nAccuracy Equality Difference           DecisionTree          0.000667\n                                       GaussianNB            0.000667\n                                       KNeighbors            0.000667\n                                       LogisticRegression    0.000667\n                                       RandomForest          0.000667\nEqual Opportunity Difference           DecisionTree          0.010667\n                                       GaussianNB            0.010667\n                                       KNeighbors            0.010667\n                                       LogisticRegression    0.010667\n                                       RandomForest          0.010667\nNegative Predictive Parity Difference  DecisionTree          0.016667\n                                       GaussianNB            0.025333\n                                       KNeighbors            0.108667\n                                       LogisticRegression    0.080667\n                                       RandomForest          0.062667\nPositive Predictive Parity Difference  DecisionTree          0.026000\n                                       GaussianNB            0.057333\n                                       KNeighbors            0.090000\n                                       LogisticRegression    0.066000\n                                       RandomForest          0.076000\nPredictive Equality Difference         DecisionTree          0.010667\n                                       GaussianNB            0.010667\n                                       KNeighbors            0.010667\n                                       LogisticRegression    0.010667\n                                       RandomForest          0.010667\nStatistical Parity                     DecisionTree          0.000667\n                                       GaussianNB            0.000667\n                                       KNeighbors            0.000667\n                                       LogisticRegression    0.000667\n                                       RandomForest          0.000667\nName: value, dtype: float64"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count nan for each metric\n",
    "fairness_results_cv.groupby(['metric', 'clf'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:07:48.684952Z",
     "end_time": "2023-04-27T11:07:48.685071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "metric                        clf           gr  \nAccuracy Equality Difference  DecisionTree  0.01    0.00\n                                            0.02    0.00\n                                            0.05    0.00\n                                            0.10    0.00\n                                            0.20    0.00\n                                                    ... \nStatistical Parity            RandomForest  0.80    0.00\n                                            0.90    0.00\n                                            0.95    0.00\n                                            0.98    0.00\n                                            0.99    0.02\nName: value, Length: 450, dtype: float64"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fairness_results_cv[\n",
    "#     (fairness_results_cv['metric'] == 'Negative Predictive Parity Difference') |\n",
    "#     (fairness_results_cv['metric'] == 'Positive Predictive Parity Difference')\n",
    "# ].groupby(['metric', 'clf', 'gr'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "fairness_results_cv.groupby(['metric', 'clf', 'gr'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:20:51.462594Z",
     "end_time": "2023-04-27T11:20:51.462716Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "metric                        clf           ir  \nAccuracy Equality Difference  DecisionTree  0.01    0.0\n                                            0.02    0.0\n                                            0.05    0.0\n                                            0.10    0.0\n                                            0.20    0.0\n                                                   ... \nStatistical Parity            RandomForest  0.80    0.0\n                                            0.90    0.0\n                                            0.95    0.0\n                                            0.98    0.0\n                                            0.99    0.0\nName: value, Length: 450, dtype: float64"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fairness_results_cv[\n",
    "#     (fairness_results_cv['metric'] == 'Negative Predictive Parity Difference') |\n",
    "#     (fairness_results_cv['metric'] == 'Positive Predictive Parity Difference')\n",
    "#     ].groupby(['metric', 'clf', 'ir'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "fairness_results_cv.groupby(['metric', 'clf', 'ir'])['value'].apply(lambda x: x.isna().sum() / x.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:20:52.482109Z",
     "end_time": "2023-04-27T11:20:52.482191Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### plot nan count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def plot_nan(fairness, ratio_type, clfs=None, metrics=None, ylim=None):\n",
    "    if clfs is None:\n",
    "        clfs = fairness['clf'].unique()\n",
    "    if metrics is None:\n",
    "        metrics = fairness['metric'].unique()\n",
    "    ratios = sorted(fairness[ratio_type].unique())\n",
    "    other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(metrics) - 1) // 2 + 1,\n",
    "                           sharex=True, sharey=True,\n",
    "                           figsize=(16, 9))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax[i % 2, i // 2].set_title(metric)\n",
    "        ax[i % 2, i // 2].set_ylabel('NaN probability')\n",
    "        ax[i % 2, i // 2].set_xlabel(ratio_type.upper())\n",
    "        ax[i % 2, i // 2].yaxis.set_major_formatter(PercentFormatter(1))\n",
    "        ax[i % 2, i // 2].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "        for j, clf in enumerate(clfs):\n",
    "            subset = fairness[\n",
    "                (fairness['clf'] == clf) &\n",
    "                (fairness[other_ratio] == .5) &\n",
    "                (fairness['metric'] == metric)\n",
    "                ]\n",
    "            counts = subset.groupby(ratio_type)['value'].apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "            ax[i % 2, i // 2].plot(ratios, counts,\n",
    "                                   label=clf, color=colours[j], marker='o', alpha=.6)\n",
    "\n",
    "    if ylim:\n",
    "        ax[0, 0].set_ylim(*ylim)\n",
    "    else:\n",
    "        ax[0, 0].set_ylim(0, ax[0, 0].get_ylim()[1] * 1.1)\n",
    "    ax[0, 0].set_xlim(0, 1)\n",
    "    ax[0, 0].legend(loc=0)\n",
    "\n",
    "    return fig\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:35.196443Z",
     "end_time": "2023-05-03T14:54:35.203882Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "for ratio_type in ['ir', 'gr']:\n",
    "    fig = plot_nan(fairness_results_cv, ratio_type,\n",
    "                   metrics=[\n",
    "                       'Accuracy Equality Difference',\n",
    "                       'Statistical Parity Difference',\n",
    "                       'Equal Opportunity Difference',\n",
    "                       'Predictive Equality Difference',\n",
    "                       'Positive Predictive Parity Difference',\n",
    "                       'Negative Predictive Parity Difference',\n",
    "                   ])\n",
    "    fig.savefig(os.path.join(plots_dir, f'fairness_nan_{ratio_type}.svg'))\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:54:37.276486Z",
     "end_time": "2023-05-03T14:54:38.163777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# pickle the results\n",
    "\n",
    "with open(os.path.join('out', 'fairness_results_cv.pkl'), 'wb') as f:\n",
    "    pickle.dump(fairness_results_cv, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T16:16:29.909151Z",
     "end_time": "2023-05-03T16:16:29.925831Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# unpickle\n",
    "\n",
    "with open(os.path.join('out', 'fairness_results_cv.pkl'), 'rb') as f:\n",
    "    fairness_results_cv = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T21:02:10.421660900Z",
     "start_time": "2023-05-04T21:02:10.406353707Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot all metrics together"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def plot_line_all(fairness: pd.DataFrame, metrics: list[str], ratio_type: str, fill='std', ylim=(-.5, .5)):\n",
    "    fig, axs = plt.subplots(\n",
    "        (len(metrics) - 1) // 2 + 1, 2,\n",
    "        sharex=True, sharey=True,\n",
    "        figsize=(14, 10)\n",
    "    )\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        axs[i // 2, i % 2].set_ylabel(metric.replace('Difference', ''))\n",
    "\n",
    "        metrics = fairness['metric'].unique()\n",
    "        clfs = fairness['clf'].unique()\n",
    "        ratios = sorted(fairness[ratio_type].unique())\n",
    "        other_ratio = 'gr' if ratio_type == 'ir' else 'ir'\n",
    "        mean, stdev, err = {}, {}, {}\n",
    "\n",
    "        for r in ratios:\n",
    "            for clf in clfs:\n",
    "                subset = fairness[\n",
    "                    (fairness[ratio_type] == r) &\n",
    "                    (fairness['clf'] == clf) &\n",
    "                    (fairness[other_ratio] == .5) &\n",
    "                    (fairness['metric'] == metric) &\n",
    "                    fairness['value'].notna()\n",
    "                    ]\n",
    "                mean[(r, clf)] = subset['value'].mean(skipna=True)\n",
    "                stdev[(r, clf)] = subset['value'].std(skipna=True)\n",
    "                err[(r, clf)] = scipy.stats.sem(subset['value'], nan_policy='omit')\n",
    "\n",
    "        axs[i // 2, i % 2].axhline(0, color='black', linestyle='--', alpha=.9, lw=1)\n",
    "\n",
    "        for j, clf in enumerate(clfs):\n",
    "            axs[i // 2, i % 2].plot(ratios, [mean[(r, clf)] for r in ratios], label=clf, color=colours[j], marker='o', lw=1, alpha=.85)\n",
    "            if fill == 'err':\n",
    "                axs[i // 2, i % 2].fill_between(ratios,\n",
    "                                [mean[(r, clf)] - err[(r, clf)] for r in ratios],\n",
    "                                [mean[(r, clf)] + err[(r, clf)] for r in ratios],\n",
    "                                alpha=.15, color=colours[j])\n",
    "            elif fill == 'std':\n",
    "                axs[i // 2, i % 2].fill_between(ratios,\n",
    "                                [mean[(r, clf)] - stdev[(r, clf)] for r in ratios],\n",
    "                                [mean[(r, clf)] + stdev[(r, clf)] for r in ratios],\n",
    "                                alpha=.15, color=colours[j])\n",
    "\n",
    "        ratios_ticks = ['0.01\\n',\n",
    "                        '0.02',\n",
    "                        '0.05',\n",
    "                        '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9',\n",
    "                        '0.95',\n",
    "                        '0.98',\n",
    "                        '\\n0.99']\n",
    "\n",
    "        axs[i // 2, i % 2].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "        axs[i // 2, i % 2].set_xticks(ratios, ratios_ticks, rotation=90)\n",
    "        axs[i // 2, i % 2].set_xlim(0, 1)\n",
    "        if i // 2 == 2:\n",
    "            axs[i // 2, i % 2].set_xlabel(x_labels[ratio_type])\n",
    "        if ylim:\n",
    "            axs[i // 2, i % 2].set_ylim(*ylim)\n",
    "\n",
    "    axs[0, 0].legend(loc=1,\n",
    "                     ncols=3)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T21:09:22.314324240Z",
     "start_time": "2023-05-04T21:09:22.271433141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ratio_type in ['ir', 'gr']:\n",
    "    fig = plot_line_all(fairness_results_cv, [\n",
    "        'Accuracy Equality Difference',\n",
    "        'Statistical Parity Difference',\n",
    "        'Equal Opportunity Difference',\n",
    "        'Predictive Equality Difference',\n",
    "        'Positive Predictive Parity Difference',\n",
    "        'Negative Predictive Parity Difference',\n",
    "    ], ratio_type, fill='std', ylim=(-.9, .9))\n",
    "    fig.savefig(os.path.join(plots_dir, f'fairness_all_{ratio_type}.svg'))\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table with classification metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f2d480cca30>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cv.groupby(['clf', 'ir', 'gr'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T20:43:33.130602900Z",
     "start_time": "2023-05-06T20:43:33.082896962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
